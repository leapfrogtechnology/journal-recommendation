{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Importing libraries and Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from nltk.tokenize import sent_tokenize,word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error,mean_squared_error\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import gensim\n",
    "import pyLDAvis.gensim\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df=pd.read_csv(\"nips-papers/papers.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'year', 'title', 'event_type', 'pdf_name', 'abstract',\n",
       "       'paper_text'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    21643\n",
       "1    15505\n",
       "2    20523\n",
       "3    19441\n",
       "4    20219\n",
       "Name: paper_text, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df['paper_text'].head().apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "author_name =pd.read_csv('nips-papers/authors.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Hisashi Suzuki</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>David Brady</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>Santosh S. Venkatesh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000</td>\n",
       "      <td>Charles Fefferman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10000</td>\n",
       "      <td>Artur Speiser</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                  name\n",
       "0      1        Hisashi Suzuki\n",
       "1     10           David Brady\n",
       "2    100  Santosh S. Venkatesh\n",
       "3   1000     Charles Fefferman\n",
       "4  10000         Artur Speiser"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "author_name.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.Text Trocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>pdf_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Self-Organization of Associative Database and ...</td>\n",
       "      <td>1-self-organization-of-associative-database-an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A Mean Field Theory of Layer IV of Visual Cort...</td>\n",
       "      <td>10-a-mean-field-theory-of-layer-iv-of-visual-c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Storing Covariance by the Associative Long-Ter...</td>\n",
       "      <td>100-storing-covariance-by-the-associative-long...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bayesian Query Construction for Neural Network...</td>\n",
       "      <td>1000-bayesian-query-construction-for-neural-ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Neural Network Ensembles, Cross Validation, an...</td>\n",
       "      <td>1001-neural-network-ensembles-cross-validation...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Using a neural net to instantiate a deformable...</td>\n",
       "      <td>1002-using-a-neural-net-to-instantiate-a-defor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Plasticity-Mediated Competitive Learning</td>\n",
       "      <td>1003-plasticity-mediated-competitive-learning.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ICEG Morphology Classification using an Analog...</td>\n",
       "      <td>1004-iceg-morphology-classification-using-an-a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Real-Time Control of a Tokamak Plasma Using Ne...</td>\n",
       "      <td>1005-real-time-control-of-a-tokamak-plasma-usi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Pulsestream Synapses with Non-Volatile Analogu...</td>\n",
       "      <td>1006-pulsestream-synapses-with-non-volatile-an...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Self-Organization of Associative Database and ...   \n",
       "1  A Mean Field Theory of Layer IV of Visual Cort...   \n",
       "2  Storing Covariance by the Associative Long-Ter...   \n",
       "3  Bayesian Query Construction for Neural Network...   \n",
       "4  Neural Network Ensembles, Cross Validation, an...   \n",
       "5  Using a neural net to instantiate a deformable...   \n",
       "6           Plasticity-Mediated Competitive Learning   \n",
       "7  ICEG Morphology Classification using an Analog...   \n",
       "8  Real-Time Control of a Tokamak Plasma Using Ne...   \n",
       "9  Pulsestream Synapses with Non-Volatile Analogu...   \n",
       "\n",
       "                                            pdf_name  \n",
       "0  1-self-organization-of-associative-database-an...  \n",
       "1  10-a-mean-field-theory-of-layer-iv-of-visual-c...  \n",
       "2  100-storing-covariance-by-the-associative-long...  \n",
       "3  1000-bayesian-query-construction-for-neural-ne...  \n",
       "4  1001-neural-network-ensembles-cross-validation...  \n",
       "5  1002-using-a-neural-net-to-instantiate-a-defor...  \n",
       "6  1003-plasticity-mediated-competitive-learning.pdf  \n",
       "7  1004-iceg-morphology-classification-using-an-a...  \n",
       "8  1005-real-time-control-of-a-tokamak-plasma-usi...  \n",
       "9  1006-pulsestream-synapses-with-non-volatile-an...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df[['title','pdf_name']].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since title and pdf_name is  same hence removing pdf_name "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, 'Oral', 'Spotlight', 'Poster'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df['event_type'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.drop(['pdf_name','event_type'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since our main object is to summarize the text hence and tagging the key words hence we donot require the event type "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>year</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>paper_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1987</td>\n",
       "      <td>Self-Organization of Associative Database and ...</td>\n",
       "      <td>Abstract Missing</td>\n",
       "      <td>767\\n\\nSELF-ORGANIZATION OF ASSOCIATIVE DATABA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>1987</td>\n",
       "      <td>A Mean Field Theory of Layer IV of Visual Cort...</td>\n",
       "      <td>Abstract Missing</td>\n",
       "      <td>683\\n\\nA MEAN FIELD THEORY OF LAYER IV OF VISU...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>1988</td>\n",
       "      <td>Storing Covariance by the Associative Long-Ter...</td>\n",
       "      <td>Abstract Missing</td>\n",
       "      <td>394\\n\\nSTORING COVARIANCE BY THE ASSOCIATIVE\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000</td>\n",
       "      <td>1994</td>\n",
       "      <td>Bayesian Query Construction for Neural Network...</td>\n",
       "      <td>Abstract Missing</td>\n",
       "      <td>Bayesian Query Construction for Neural\\nNetwor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1001</td>\n",
       "      <td>1994</td>\n",
       "      <td>Neural Network Ensembles, Cross Validation, an...</td>\n",
       "      <td>Abstract Missing</td>\n",
       "      <td>Neural Network Ensembles, Cross\\nValidation, a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  year                                              title  \\\n",
       "0     1  1987  Self-Organization of Associative Database and ...   \n",
       "1    10  1987  A Mean Field Theory of Layer IV of Visual Cort...   \n",
       "2   100  1988  Storing Covariance by the Associative Long-Ter...   \n",
       "3  1000  1994  Bayesian Query Construction for Neural Network...   \n",
       "4  1001  1994  Neural Network Ensembles, Cross Validation, an...   \n",
       "\n",
       "           abstract                                         paper_text  \n",
       "0  Abstract Missing  767\\n\\nSELF-ORGANIZATION OF ASSOCIATIVE DATABA...  \n",
       "1  Abstract Missing  683\\n\\nA MEAN FIELD THEORY OF LAYER IV OF VISU...  \n",
       "2  Abstract Missing  394\\n\\nSTORING COVARIANCE BY THE ASSOCIATIVE\\n...  \n",
       "3  Abstract Missing  Bayesian Query Construction for Neural\\nNetwor...  \n",
       "4  Abstract Missing  Neural Network Ensembles, Cross\\nValidation, a...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "paper_separate_abstract = data_df[(data_df['abstract']!='Abstract Missing')].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([ 941, 1067, 2384, 2385, 2388, 2389, 2390, 2393, 2394, 2396,\n",
       "            ...\n",
       "            6937, 6938, 6939, 6940, 6941, 6943, 6944, 6945, 6946, 6947],\n",
       "           dtype='int64', length=3924)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paper_separate_abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3924"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_df[(data_df['abstract']!='Abstract Missing')].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-negative matrix factorization (NMF) has previously been shown to \r\n",
      "be a useful decomposition for multivariate data. Two different multi- \r\n",
      "plicative algorithms for NMF are analyzed. They differ only slightly in \r\n",
      "the multiplicative factor used in the update rules. One algorithm can be \r\n",
      "shown to minimize the conventional least squares error while the other \r\n",
      "minimizes the generalized Kullback-Leibler divergence. The monotonic \r\n",
      "convergence of both algorithms can be proven using an auxiliary func- \r\n",
      "tion analogous to that used for proving convergence of the Expectation- \r\n",
      "Maximization algorithm. The algorithms can also be interpreted as diag- \r\n",
      "onally rescaled gradient descent, where the rescaling factor is optimally \r\n",
      "chosen to ensure convergence. \n"
     ]
    }
   ],
   "source": [
    "print(data_df['abstract'].iloc[941])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = data_df.iloc[paper_separate_abstract]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.drop('paper_text',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since abstract is present in 3924 text hence removing the full papers of this journals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.reset_index(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.drop('index',axis=1,inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-negative matrix factorization (NMF) has previously been shown to \r\n",
      "be a useful decomposition for multivariate data. Two different multi- \r\n",
      "plicative algorithms for NMF are analyzed. They differ only slightly in \r\n",
      "the multiplicative factor used in the update rules. One algorithm can be \r\n",
      "shown to minimize the conventional least squares error while the other \r\n",
      "minimizes the generalized Kullback-Leibler divergence. The monotonic \r\n",
      "convergence of both algorithms can be proven using an auxiliary func- \r\n",
      "tion analogous to that used for proving convergence of the Expectation- \r\n",
      "Maximization algorithm. The algorithms can also be interpreted as diag- \r\n",
      "onally rescaled gradient descent, where the rescaling factor is optimally \r\n",
      "chosen to ensure convergence. \n"
     ]
    }
   ],
   "source": [
    "print(data_df['abstract'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having the word count "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>year</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1861</td>\n",
       "      <td>2000</td>\n",
       "      <td>Algorithms for Non-negative Matrix Factorization</td>\n",
       "      <td>Non-negative matrix factorization (NMF) has pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1975</td>\n",
       "      <td>2001</td>\n",
       "      <td>Characterizing Neural Gain Control using Spike...</td>\n",
       "      <td>Spike-triggered averaging techniques are effec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3163</td>\n",
       "      <td>2007</td>\n",
       "      <td>Competition Adds Complexity</td>\n",
       "      <td>It is known that determinining whether a DEC-P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3164</td>\n",
       "      <td>2007</td>\n",
       "      <td>Efficient Principled Learning of Thin Junction...</td>\n",
       "      <td>We present the first truly polynomial algorith...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3167</td>\n",
       "      <td>2007</td>\n",
       "      <td>Regularized Boost for Semi-Supervised Learning</td>\n",
       "      <td>Semi-supervised inductive learning concerns ho...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  year                                              title  \\\n",
       "0  1861  2000   Algorithms for Non-negative Matrix Factorization   \n",
       "1  1975  2001  Characterizing Neural Gain Control using Spike...   \n",
       "2  3163  2007                        Competition Adds Complexity   \n",
       "3  3164  2007  Efficient Principled Learning of Thin Junction...   \n",
       "4  3167  2007     Regularized Boost for Semi-Supervised Learning   \n",
       "\n",
       "                                            abstract  \n",
       "0  Non-negative matrix factorization (NMF) has pr...  \n",
       "1  Spike-triggered averaging techniques are effec...  \n",
       "2  It is known that determinining whether a DEC-P...  \n",
       "3  We present the first truly polynomial algorith...  \n",
       "4  Semi-supervised inductive learning concerns ho...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_processing(df,col):\n",
    "    temp_df = df[col]\n",
    "    # 1.Remove punctuation\n",
    "    temp_df = temp_df.apply(lambda x: re.sub('[[^a-zA-Z]]',' ',x))\n",
    "    # 2. converting lower case\n",
    "    temp_df = temp_df.apply(lambda x: x.lower())\n",
    "    # 3. removing special character and digit\n",
    "    temp_df = temp_df.apply(lambda x: re.sub(\"(\\\\d|\\\\W)+\",\" \",x))\n",
    "    return temp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df['abstract'] =text_processing(data_df,'abstract')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "non negative matrix factorization nmf has previously been shown to be a useful decomposition for multivariate data two different multi plicative algorithms for nmf are analyzed they differ only slightly in the multiplicative factor used in the update rules one algorithm can be shown to minimize the conventional least squares error while the other minimizes the generalized kullback leibler divergence the monotonic convergence of both algorithms can be proven using an auxiliary func tion analogous to that used for proving convergence of the expectation maximization algorithm the algorithms can also be interpreted as diag onally rescaled gradient descent where the rescaling factor is optimally chosen to ensure convergence \n"
     ]
    }
   ],
   "source": [
    "print(data_df['abstract'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_lemmatize(df,col):\n",
    "    temp_df =df[col]\n",
    "    #1. Word Tokenization:\n",
    "    temp_df = temp_df.apply(lambda x : word_tokenize(x))\n",
    "    word_no_pre = temp_df.apply(lambda x: len(x))\n",
    "    temp_df = temp_df.apply(lambda x : [i for i in x if not i in stopwords.words('english')])\n",
    "    #2. Word Lemmatization:\n",
    "    lemmatize =WordNetLemmatizer()\n",
    "    temp_df = temp_df.apply(lambda x: [lemmatize.lemmatize(i) for i in x])\n",
    "    word_no_post =temp_df.apply(lambda x: len(x))\n",
    "    temp_df = temp_df.apply(lambda x: \" \".join(x))\n",
    "    return temp_df,word_no_pre,word_no_post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_df['abstract_post'],data_df['word_count_pre'],data_df['word_count_post']=tokenize_lemmatize(data_df,'abstract')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>year</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>abstract_post</th>\n",
       "      <th>word_count_pre</th>\n",
       "      <th>word_count_post</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1861</td>\n",
       "      <td>2000</td>\n",
       "      <td>Algorithms for Non-negative Matrix Factorization</td>\n",
       "      <td>non negative matrix factorization nmf has prev...</td>\n",
       "      <td>non negative matrix factorization nmf previous...</td>\n",
       "      <td>108</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1975</td>\n",
       "      <td>2001</td>\n",
       "      <td>Characterizing Neural Gain Control using Spike...</td>\n",
       "      <td>spike triggered averaging techniques are effec...</td>\n",
       "      <td>spike triggered averaging technique effective ...</td>\n",
       "      <td>83</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3163</td>\n",
       "      <td>2007</td>\n",
       "      <td>Competition Adds Complexity</td>\n",
       "      <td>it is known that determinining whether a dec p...</td>\n",
       "      <td>known determinining whether dec pomdp namely c...</td>\n",
       "      <td>70</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3164</td>\n",
       "      <td>2007</td>\n",
       "      <td>Efficient Principled Learning of Thin Junction...</td>\n",
       "      <td>we present the first truly polynomial algorith...</td>\n",
       "      <td>present first truly polynomial algorithm learn...</td>\n",
       "      <td>144</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3167</td>\n",
       "      <td>2007</td>\n",
       "      <td>Regularized Boost for Semi-Supervised Learning</td>\n",
       "      <td>semi supervised inductive learning concerns ho...</td>\n",
       "      <td>semi supervised inductive learning concern lea...</td>\n",
       "      <td>123</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  year                                              title  \\\n",
       "0  1861  2000   Algorithms for Non-negative Matrix Factorization   \n",
       "1  1975  2001  Characterizing Neural Gain Control using Spike...   \n",
       "2  3163  2007                        Competition Adds Complexity   \n",
       "3  3164  2007  Efficient Principled Learning of Thin Junction...   \n",
       "4  3167  2007     Regularized Boost for Semi-Supervised Learning   \n",
       "\n",
       "                                            abstract  \\\n",
       "0  non negative matrix factorization nmf has prev...   \n",
       "1  spike triggered averaging techniques are effec...   \n",
       "2  it is known that determinining whether a dec p...   \n",
       "3  we present the first truly polynomial algorith...   \n",
       "4  semi supervised inductive learning concerns ho...   \n",
       "\n",
       "                                       abstract_post  word_count_pre  \\\n",
       "0  non negative matrix factorization nmf previous...             108   \n",
       "1  spike triggered averaging technique effective ...              83   \n",
       "2  known determinining whether dec pomdp namely c...              70   \n",
       "3  present first truly polynomial algorithm learn...             144   \n",
       "4  semi supervised inductive learning concern lea...             123   \n",
       "\n",
       "   word_count_post  \n",
       "0               67  \n",
       "1               52  \n",
       "2               40  \n",
       "3               89  \n",
       "4               81  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    " token_df = data_df['abstract_post'].apply(lambda x:x.split(\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# creating word dictionary\n",
    "dictionary = gensim.corpora.Dictionary(token_df)\n",
    "#converting dictionary into a bag of words \n",
    "word_map =[dictionary.doc2bow(text) for text in token_df]\n",
    "# Build LDA model\n",
    "lda_model = gensim.models.ldamodel.LdaModel(corpus=word_map,\n",
    "                                           id2word=dictionary,\n",
    "                                           num_topics=4, \n",
    "                                           random_state=100,\n",
    "                                           update_every=1,\n",
    "                                           chunksize=100,\n",
    "                                           passes=50,\n",
    "                                           per_word_topics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el141221402019799297281769053404\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el141221402019799297281769053404_data = {\"mdsDat\": {\"x\": [0.09655097012287071, -0.03384449224255237, -0.23203029581200282, 0.16932381793168402], \"y\": [0.1198055366767252, -0.15977625418529062, 0.05915694063803448, -0.019186223129469174], \"topics\": [1, 2, 3, 4], \"cluster\": [1, 1, 1, 1], \"Freq\": [29.222599029541016, 27.59147834777832, 22.493318557739258, 20.69260025024414]}, \"tinfo\": {\"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\"], \"Freq\": [2491.0, 4864.0, 1214.0, 1106.0, 1027.0, 4097.0, 1067.0, 876.0, 924.0, 725.0, 871.0, 3034.0, 3151.0, 562.0, 1745.0, 497.0, 605.0, 808.0, 3412.0, 1019.0, 445.0, 966.0, 1010.0, 1471.0, 444.0, 560.0, 1033.0, 767.0, 524.0, 406.0, 1066.421875, 524.0167236328125, 494.31451416015625, 426.5543518066406, 434.4791259765625, 282.212890625, 257.7882080078125, 301.5935363769531, 261.29730224609375, 243.1927032470703, 237.0117645263672, 232.43341064453125, 222.82858276367188, 216.90830993652344, 194.82656860351562, 192.06304931640625, 168.38002014160156, 164.80027770996094, 161.7863006591797, 138.6405792236328, 147.02090454101562, 128.52052307128906, 133.44703674316406, 122.05033111572266, 120.64063262939453, 131.0443572998047, 111.31549072265625, 113.55209350585938, 107.35347747802734, 120.56710815429688, 134.8349151611328, 687.1519165039062, 459.3267517089844, 591.127685546875, 1233.016357421875, 301.7248840332031, 2463.906982421875, 718.8732299804688, 632.4948120117188, 746.0783081054688, 322.18603515625, 374.73260498046875, 1601.6534423828125, 506.8582763671875, 1615.6353759765625, 503.9040832519531, 402.40631103515625, 476.9911193847656, 851.0294189453125, 686.321533203125, 621.00634765625, 419.3380126953125, 435.0977478027344, 417.0374755859375, 510.8883361816406, 381.5591735839844, 363.2473449707031, 420.0256042480469, 497.4368591308594, 396.3042907714844, 405.2689208984375, 924.0291748046875, 870.2886352539062, 604.6651000976562, 482.9964599609375, 350.2593078613281, 325.47637939453125, 321.1607971191406, 284.2388916015625, 272.0699157714844, 191.33250427246094, 176.80963134765625, 169.0230255126953, 140.33477783203125, 137.2510528564453, 132.45831298828125, 132.45831298828125, 140.2954864501953, 125.45447540283203, 112.31002807617188, 111.68154907226562, 103.62357330322266, 108.65775299072266, 104.72004699707031, 100.15694427490234, 96.46961212158203, 104.55269622802734, 89.35568237304688, 81.49771118164062, 93.52617645263672, 79.81253814697266, 546.3327026367188, 574.9542846679688, 317.1238708496094, 3074.738525390625, 544.33203125, 412.01666259765625, 583.4940185546875, 1197.9312744140625, 1844.2962646484375, 534.635009765625, 239.33221435546875, 838.3582763671875, 532.8782348632812, 437.06365966796875, 209.6283416748047, 626.7440795898438, 1161.5062255859375, 487.67327880859375, 1181.07080078125, 719.4107055664062, 630.1466064453125, 481.2740783691406, 420.4405822753906, 935.87060546875, 398.79510498046875, 636.3737182617188, 434.3625183105469, 491.3789978027344, 476.7410888671875, 438.9520263671875, 482.2485046386719, 1213.875, 1106.0751953125, 875.4016723632812, 443.9631652832031, 397.48785400390625, 356.2629089355469, 327.29046630859375, 312.01611328125, 307.2052917480469, 235.3412322998047, 238.01023864746094, 216.30848693847656, 212.9214324951172, 203.54425048828125, 191.04513549804688, 186.29928588867188, 184.78378295898438, 174.30531311035156, 157.68296813964844, 142.6378936767578, 141.00625610351562, 129.40771484375, 123.88713073730469, 121.92095947265625, 116.74957275390625, 124.09111022949219, 107.37325286865234, 106.69203186035156, 106.52704620361328, 104.55276489257812, 129.98504638671875, 108.99837493896484, 447.6212463378906, 2122.748779296875, 157.07138061523438, 231.60433959960938, 182.61058044433594, 674.836669921875, 469.5903015136719, 804.6113891601562, 389.24835205078125, 412.4420166015625, 1524.427734375, 193.0816650390625, 315.1910705566406, 420.3336486816406, 361.494140625, 424.0233154296875, 592.6199951171875, 398.1319885253906, 445.3078308105469, 282.4111328125, 324.3498229980469, 339.00634765625, 394.46221923828125, 310.8801574707031, 354.8722839355469, 315.7723388671875, 311.3598937988281, 1026.3896484375, 724.8540649414062, 561.7866821289062, 497.0149841308594, 445.05902099609375, 405.927490234375, 244.0760040283203, 234.981689453125, 229.76219177246094, 216.21559143066406, 201.31568908691406, 188.63584899902344, 182.67022705078125, 180.46902465820312, 177.4002227783203, 169.02354431152344, 147.59188842773438, 162.57496643066406, 135.69309997558594, 127.26597595214844, 125.07026672363281, 108.68003845214844, 113.70806121826172, 103.93060302734375, 99.0772705078125, 103.50306701660156, 96.98436737060547, 97.1795883178711, 92.1338119506836, 92.07189178466797, 331.8019104003906, 427.88134765625, 448.9684143066406, 255.97274780273438, 557.56787109375, 168.094970703125, 354.4187316894531, 629.4991455078125, 530.4072875976562, 455.2216796875, 304.02099609375, 1176.537353515625, 273.3083801269531, 259.43695068359375, 393.35784912109375, 796.3464965820312, 424.2274169921875, 761.5164794921875, 377.6565856933594, 697.4124755859375, 487.7503356933594, 429.7647399902344, 368.4609375, 350.07867431640625, 287.549072265625, 330.3875427246094, 281.0129089355469, 293.65716552734375, 294.2675476074219], \"Term\": [\"network\", \"model\", \"neural\", \"image\", \"matrix\", \"algorithm\", \"bound\", \"deep\", \"inference\", \"kernel\", \"graph\", \"problem\", \"data\", \"estimator\", \"function\", \"sparse\", \"latent\", \"n\", \"learning\", \"optimization\", \"regression\", \"gradient\", \"linear\", \"task\", \"architecture\", \"bayesian\", \"training\", \"optimal\", \"loss\", \"x\", \"bound\", \"loss\", \"policy\", \"regret\", \"online\", \"game\", \"reward\", \"agent\", \"item\", \"submodular\", \"bandit\", \"risk\", \"reinforcement\", \"query\", \"oracle\", \"batch\", \"upper\", \"epsilon\", \"sqrt\", \"learner\", \"ranking\", \"arm\", \"exploration\", \"expected\", \"worst\", \"recommendation\", \"active\", \"rl\", \"sgd\", \"b\", \"meta\", \"optimal\", \"objective\", \"setting\", \"function\", \"decision\", \"algorithm\", \"gradient\", \"stochastic\", \"optimization\", \"lower\", \"value\", \"problem\", \"case\", \"learning\", \"convergence\", \"guarantee\", \"rate\", \"show\", \"result\", \"time\", \"study\", \"class\", \"first\", \"paper\", \"provide\", \"convex\", \"new\", \"method\", \"also\", \"based\", \"inference\", \"graph\", \"latent\", \"variational\", \"posterior\", \"tree\", \"node\", \"cluster\", \"probabilistic\", \"causal\", \"edge\", \"graphical\", \"topic\", \"chain\", \"monte\", \"carlo\", \"community\", \"shot\", \"mcmc\", \"hash\", \"marginal\", \"affinity\", \"propagation\", \"partition\", \"attribute\", \"generating\", \"message\", \"discovery\", \"spns\", \"flexibility\", \"bayesian\", \"clustering\", \"likelihood\", \"model\", \"variable\", \"world\", \"process\", \"approach\", \"data\", \"structure\", \"similarity\", \"distribution\", \"real\", \"datasets\", \"structured\", \"state\", \"method\", \"demonstrate\", \"learning\", \"based\", \"propose\", \"parameter\", \"art\", \"algorithm\", \"present\", \"problem\", \"proposed\", \"task\", \"using\", \"new\", \"show\", \"neural\", \"image\", \"deep\", \"architecture\", \"layer\", \"human\", \"trained\", \"visual\", \"convolutional\", \"recurrent\", \"train\", \"neuron\", \"recognition\", \"motion\", \"brain\", \"scene\", \"word\", \"population\", \"gan\", \"video\", \"activity\", \"spike\", \"frame\", \"pattern\", \"cifar\", \"parsing\", \"translation\", \"imagenet\", \"spatial\", \"activation\", \"dynamical\", \"generator\", \"object\", \"network\", \"temporal\", \"end\", \"future\", \"training\", \"representation\", \"task\", \"input\", \"system\", \"model\", \"attention\", \"dynamic\", \"feature\", \"information\", \"state\", \"learning\", \"using\", \"show\", \"different\", \"performance\", \"time\", \"data\", \"two\", \"method\", \"propose\", \"result\", \"matrix\", \"kernel\", \"estimator\", \"sparse\", \"regression\", \"x\", \"norm\", \"l\", \"regularization\", \"coordinate\", \"tensor\", \"spectral\", \"covariance\", \"r\", \"subspace\", \"sparsity\", \"recovery\", \"moment\", \"divergence\", \"square\", \"dimensionality\", \"regularized\", \"coefficient\", \"manifold\", \"ell_\", \"projection\", \"lasso\", \"additive\", \"column\", \"completion\", \"rank\", \"dimensional\", \"estimation\", \"dimension\", \"n\", \"decomposition\", \"low\", \"linear\", \"analysis\", \"k\", \"vector\", \"method\", \"statistical\", \"mean\", \"high\", \"problem\", \"sample\", \"data\", \"non\", \"algorithm\", \"show\", \"result\", \"function\", \"paper\", \"convex\", \"propose\", \"error\", \"proposed\", \"distribution\"], \"Total\": [2491.0, 4864.0, 1214.0, 1106.0, 1027.0, 4097.0, 1067.0, 876.0, 924.0, 725.0, 871.0, 3034.0, 3151.0, 562.0, 1745.0, 497.0, 605.0, 808.0, 3412.0, 1019.0, 445.0, 966.0, 1010.0, 1471.0, 444.0, 560.0, 1033.0, 767.0, 524.0, 406.0, 1067.19384765625, 524.8057250976562, 495.0713806152344, 427.2944641113281, 435.2621154785156, 282.98443603515625, 258.5444030761719, 302.4913330078125, 262.0914611816406, 243.9405975341797, 237.75399780273438, 233.2012481689453, 223.61099243164062, 217.6842041015625, 195.58450317382812, 192.86952209472656, 169.14366149902344, 165.5795440673828, 162.56399536132812, 139.3961181640625, 147.843505859375, 129.2706756591797, 134.2356414794922, 122.81144714355469, 121.39411163330078, 131.8917999267578, 112.08423614501953, 114.34774017333984, 108.11569213867188, 121.42814636230469, 136.03933715820312, 767.38818359375, 536.7777709960938, 745.6185302734375, 1745.409423828125, 349.1505432128906, 4097.43359375, 966.5419921875, 835.36669921875, 1019.393798828125, 382.6258850097656, 474.7118225097656, 3034.625, 722.2798461914062, 3412.71923828125, 742.529296875, 548.2184448242188, 750.9205322265625, 2266.336181640625, 1725.5821533203125, 1444.2349853515625, 714.98095703125, 860.377197265625, 828.5487670898438, 1439.075927734375, 756.6575317382812, 651.287841796875, 1213.55322265625, 3190.352783203125, 1064.521484375, 1704.9542236328125, 924.7571411132812, 871.0263061523438, 605.4382934570312, 483.74249267578125, 350.99127197265625, 326.2037658691406, 321.90850830078125, 284.9983215332031, 272.8007507324219, 192.06991577148438, 177.5656280517578, 169.74813842773438, 141.05482482910156, 137.97779846191406, 133.17672729492188, 133.17672729492188, 141.08151245117188, 126.24968719482422, 113.02576446533203, 112.44925689697266, 104.35236358642578, 109.4306640625, 105.47200775146484, 100.87996673583984, 97.25779724121094, 105.43804931640625, 90.12187194824219, 82.2642593383789, 94.42444610595703, 80.58180236816406, 560.8948364257812, 643.9927978515625, 360.7156066894531, 4864.55517578125, 689.5029296875, 502.764892578125, 770.7487182617188, 1864.2781982421875, 3151.68310546875, 735.8073120117188, 280.6962890625, 1360.751953125, 826.0984497070312, 745.3451538085938, 258.8603210449219, 1281.3759765625, 3190.352783203125, 897.3411865234375, 3412.71923828125, 1704.9542236328125, 1552.1761474609375, 1003.7877197265625, 837.7308349609375, 4097.43359375, 756.7881469726562, 3034.625, 978.3854370117188, 1471.9937744140625, 1341.14453125, 1213.55322265625, 2266.336181640625, 1214.625, 1106.8201904296875, 876.1702880859375, 444.7220153808594, 398.2283020019531, 357.004638671875, 328.0404968261719, 312.7421875, 307.9373779296875, 236.0771026611328, 238.7828369140625, 217.03553771972656, 213.65757751464844, 204.29246520996094, 191.77784729003906, 187.024169921875, 185.5386505126953, 175.1150665283203, 158.49267578125, 143.37974548339844, 141.7404327392578, 130.1398162841797, 124.63262939453125, 122.67546081542969, 117.50080108642578, 124.92132568359375, 108.11420440673828, 107.44285583496094, 107.28425598144531, 105.29898834228516, 131.04684448242188, 109.82038879394531, 482.5093078613281, 2491.771728515625, 167.30279541015625, 265.6035461425781, 200.64418029785156, 1033.062744140625, 678.5617065429688, 1471.9937744140625, 569.8284912109375, 639.3709716796875, 4864.55517578125, 233.0531768798828, 525.98779296875, 959.359375, 796.353759765625, 1281.3759765625, 3412.71923828125, 1341.14453125, 2266.336181640625, 625.64306640625, 1198.5302734375, 1444.2349853515625, 3151.68310546875, 1106.1258544921875, 3190.352783203125, 1552.1761474609375, 1725.5821533203125, 1027.1197509765625, 725.58740234375, 562.5209350585938, 497.7535095214844, 445.83465576171875, 406.66168212890625, 244.79052734375, 235.72862243652344, 230.49639892578125, 216.95965576171875, 202.043212890625, 189.36293029785156, 183.3946990966797, 181.20164489746094, 178.15713500976562, 169.7563018798828, 148.30923461914062, 163.37022399902344, 136.44895935058594, 127.9854507446289, 125.81204223632812, 109.41133880615234, 114.48445892333984, 104.66431427001953, 99.78520202636719, 104.2507553100586, 97.68729400634766, 97.92373657226562, 92.84929656982422, 92.79228973388672, 346.1828308105469, 535.8409423828125, 590.2611694335938, 309.458984375, 808.1602172851562, 190.01638793945312, 484.4627990722656, 1010.4605102539062, 866.9583740234375, 737.2548828125, 441.21612548828125, 3190.352783203125, 409.28802490234375, 378.51995849609375, 759.6634521484375, 3034.625, 974.7119750976562, 3151.68310546875, 838.6239624023438, 4097.43359375, 2266.336181640625, 1725.5821533203125, 1745.409423828125, 1439.075927734375, 651.287841796875, 1552.1761474609375, 627.4974365234375, 978.3854370117188, 1360.751953125], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 1.2295000553131104, 1.228700041770935, 1.228700041770935, 1.2285000085830688, 1.2283999919891357, 1.2274999618530273, 1.2273000478744507, 1.2273000478744507, 1.2272000312805176, 1.2272000312805176, 1.2271000146865845, 1.2268999814987183, 1.226699948310852, 1.226699948310852, 1.2263000011444092, 1.2259999513626099, 1.2257000207901, 1.2254999876022339, 1.2253999710083008, 1.2247999906539917, 1.2245999574661255, 1.2244000434875488, 1.2243000268936157, 1.2239999771118164, 1.2239999771118164, 1.2237999439239502, 1.2232999801635742, 1.2231999635696411, 1.2231999635696411, 1.223099946975708, 1.2213000059127808, 1.1197999715805054, 1.0743999481201172, 0.9980000257492065, 0.8827000260353088, 1.0842000246047974, 0.7215999960899353, 0.9341999888420105, 0.9520000219345093, 0.9180999994277954, 1.0583000183105469, 0.9937000274658203, 0.5911999940872192, 0.8759999871253967, 0.48240000009536743, 0.8425999879837036, 0.9210000038146973, 0.7764000296592712, 0.2508000135421753, 0.3082999885082245, 0.3862000107765198, 0.6966000199317932, 0.5483999848365784, 0.5436999797821045, 0.19460000097751617, 0.5455999970436096, 0.646399974822998, 0.16920000314712524, -0.6281999945640564, 0.24210000038146973, -0.20649999380111694, 1.2869000434875488, 1.2868000268936157, 1.2863999605178833, 1.2861000299453735, 1.285599946975708, 1.2854000329971313, 1.2853000164031982, 1.284999966621399, 1.284999966621399, 1.2838000059127808, 1.283400058746338, 1.283400058746338, 1.2825000286102295, 1.2824000120162964, 1.2822999954223633, 1.2822999954223633, 1.282099962234497, 1.2812999486923218, 1.2812999486923218, 1.2807999849319458, 1.2806999683380127, 1.2805999517440796, 1.280500054359436, 1.280500054359436, 1.2795000076293945, 1.2791999578475952, 1.279099941253662, 1.2783000469207764, 1.2781000137329102, 1.2781000137329102, 1.2613999843597412, 1.174299955368042, 1.1589000225067139, 0.8288999795913696, 1.051300048828125, 1.0886000394821167, 1.0092999935150146, 0.8453999757766724, 0.751800000667572, 0.9682999849319458, 1.1282000541687012, 0.8033000230789185, 0.8492000102996826, 0.7538999915122986, 1.07669997215271, 0.5724999904632568, 0.27720001339912415, 0.6779000163078308, 0.22660000622272491, 0.42480000853538513, 0.3862000107765198, 0.5526000261306763, 0.5982999801635742, -0.1889999955892563, 0.6470000147819519, -0.274399995803833, 0.475600004196167, 0.19050000607967377, 0.2533999979496002, 0.27070000767707825, -0.259799987077713, 1.4912999868392944, 1.4912999868392944, 1.4910999536514282, 1.4902000427246094, 1.4901000261306763, 1.48989999294281, 1.4896999597549438, 1.4895999431610107, 1.4895999431610107, 1.488800048828125, 1.488700032234192, 1.4886000156402588, 1.4884999990463257, 1.4882999658584595, 1.4881000518798828, 1.4881000518798828, 1.4879000186920166, 1.4873000383377075, 1.486799955368042, 1.486799955368042, 1.486799955368042, 1.486299991607666, 1.4859999418258667, 1.48580002784729, 1.4854999780654907, 1.4852999448776245, 1.4851000308990479, 1.4848999977111816, 1.4848999977111816, 1.4847999811172485, 1.4838000535964966, 1.4844000339508057, 1.4169000387191772, 1.3316999673843384, 1.4287999868392944, 1.3550000190734863, 1.3977999687194824, 1.066100001335144, 1.1238000392913818, 0.8878999948501587, 1.11080002784729, 1.0535999536514282, 0.33160001039505005, 1.3037999868392944, 0.9799000024795532, 0.666700005531311, 0.7021999955177307, 0.38609999418258667, -0.2587999999523163, 0.2775000035762787, -0.13519999384880066, 0.6965000033378601, 0.18490000069141388, 0.04259999841451645, -0.5861999988555908, 0.22269999980926514, -0.704200029373169, -0.10040000081062317, -0.22040000557899475, 1.5746999979019165, 1.5743999481201172, 1.5741000175476074, 1.5738999843597412, 1.573699951171875, 1.5736000537872314, 1.5724999904632568, 1.5721999406814575, 1.5721999406814575, 1.5720000267028809, 1.5717999935150146, 1.5714999437332153, 1.5714000463485718, 1.5713000297546387, 1.5710999965667725, 1.5710999965667725, 1.5705000162124634, 1.5705000162124634, 1.5698000192642212, 1.5698000192642212, 1.5694999694824219, 1.5686999559402466, 1.568600058555603, 1.5684000253677368, 1.5683000087738037, 1.5681999921798706, 1.5681999921798706, 1.5678000450134277, 1.5677000284194946, 1.5676000118255615, 1.5329999923706055, 1.3503999710083008, 1.301800012588501, 1.385599970817566, 1.204200029373169, 1.4528000354766846, 1.2627999782562256, 1.1022000312805176, 1.0839999914169312, 1.0931999683380127, 1.2029999494552612, 0.5777999758720398, 1.1715999841690063, 1.19760000705719, 0.9172000288963318, 0.23759999871253967, 0.7434999942779541, 0.1550000011920929, 0.7775999903678894, -0.19529999792575836, 0.03929999843239784, 0.18529999256134033, 0.019999999552965164, 0.16179999709129333, 0.7577999830245972, 0.028200000524520874, 0.7720999717712402, 0.3718999922275543, 0.04410000145435333], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -4.606200218200684, -5.316800117492676, -5.375100135803223, -5.522600173950195, -5.504199981689453, -5.9355998039245605, -6.026199817657471, -5.869200229644775, -6.012599945068359, -6.084400177001953, -6.110199928283691, -6.129700183868408, -6.171899795532227, -6.198800086975098, -6.30620002746582, -6.320499897003174, -6.452099800109863, -6.473599910736084, -6.492000102996826, -6.646399974822998, -6.587699890136719, -6.7221999168396, -6.684599876403809, -6.773900032043457, -6.7855000495910645, -6.7027997970581055, -6.865900039672852, -6.8460001945495605, -6.902200222015381, -6.786099910736084, -6.674200057983398, -5.0457000732421875, -5.448500156402588, -5.196300029754639, -4.461100101470947, -5.868800163269043, -3.7688000202178955, -5.0005998611450195, -5.128600120544434, -4.963500022888184, -5.803199768066406, -5.652100086212158, -4.19950008392334, -5.350100040435791, -4.190800189971924, -5.355899810791016, -5.5808000564575195, -5.410799980163574, -4.831900119781494, -5.046999931335449, -5.146999835968018, -5.539599895477295, -5.502699851989746, -5.545100212097168, -5.342100143432617, -5.633999824523926, -5.683199882507324, -5.538000106811523, -5.368800163269043, -5.596099853515625, -5.573699951171875, -4.6921000480651855, -4.751999855041504, -5.116199970245361, -5.34089994430542, -5.662199974060059, -5.735599994659424, -5.748899936676025, -5.870999813079834, -5.91480016708374, -6.2667999267578125, -6.345799922943115, -6.3907999992370605, -6.5767998695373535, -6.599100112915039, -6.6346001625061035, -6.6346001625061035, -6.577099800109863, -6.688899993896484, -6.799600124359131, -6.805200099945068, -6.880099773406982, -6.832699775695801, -6.86959981918335, -6.914100170135498, -6.951600074768066, -6.871200084686279, -7.028200149536133, -7.120299816131592, -6.982600212097168, -7.141200065612793, -5.217599868774414, -5.166600227355957, -5.761600017547607, -3.4899001121520996, -5.22130012512207, -5.499800205230713, -5.151800155639648, -4.432499885559082, -4.000999927520752, -5.239299774169922, -6.043000221252441, -4.789400100708008, -5.242599964141846, -5.440800189971924, -6.17549991607666, -5.0802998542785645, -4.463399887084961, -5.331200122833252, -4.446700096130371, -4.942399978637695, -5.074900150299072, -5.344399929046631, -5.479599952697754, -4.6793999671936035, -5.532400131225586, -5.065100193023682, -5.447000026702881, -5.323599815368652, -5.353899955749512, -5.436500072479248, -5.342400074005127, -4.215000152587891, -4.308000087738037, -4.541900157928467, -5.220799922943115, -5.331399917602539, -5.440899848937988, -5.525700092315674, -5.573500156402588, -5.589099884033203, -5.855500221252441, -5.844299793243408, -5.939899921417236, -5.955699920654297, -6.000699996948242, -6.0640997886657715, -6.089200019836426, -6.097400188446045, -6.155799865722656, -6.25600004196167, -6.356299877166748, -6.367800235748291, -6.45359992980957, -6.497200012207031, -6.513199806213379, -6.55649995803833, -6.49560022354126, -6.6402997970581055, -6.646599769592285, -6.648200035095215, -6.666900157928467, -6.44920015335083, -6.625199794769287, -5.212600231170654, -3.656100034713745, -6.259900093078613, -5.871500015258789, -6.1092000007629395, -4.80210018157959, -5.164700031280518, -4.626200199127197, -5.352399826049805, -5.29449987411499, -3.9872000217437744, -6.053500175476074, -5.563399791717529, -5.2754998207092285, -5.426300048828125, -5.2667999267578125, -4.932000160217285, -5.329800128936768, -5.217800140380859, -5.6732001304626465, -5.534800052642822, -5.490600109100342, -5.339099884033203, -5.577199935913086, -5.444799900054932, -5.561600208282471, -5.5756001472473145, -4.299300193786621, -4.647200107574463, -4.9019999504089355, -5.024499893188477, -5.134900093078613, -5.2270002365112305, -5.7357001304626465, -5.773600101470947, -5.79610013961792, -5.856900215148926, -5.928299903869629, -5.993299961090088, -6.025400161743164, -6.037600040435791, -6.054699897766113, -6.103099822998047, -6.238699913024902, -6.142000198364258, -6.322700023651123, -6.386899948120117, -6.404300212860107, -6.5447001457214355, -6.499499797821045, -6.589399814605713, -6.637199878692627, -6.593500137329102, -6.658599853515625, -6.656599998474121, -6.70989990234375, -6.710599899291992, -5.428599834442139, -5.174300193786621, -5.126200199127197, -5.6880998611450195, -4.9095001220703125, -6.10860013961792, -5.36269998550415, -4.7881999015808105, -4.959499835968018, -5.112299919128418, -5.515999794006348, -4.162799835205078, -5.622499942779541, -5.674600124359131, -5.258399963378906, -4.553100109100342, -5.1828999519348145, -4.597799777984619, -5.299099922180176, -4.685800075531006, -5.043300151824951, -5.169899940490723, -5.323800086975098, -5.375, -5.571700096130371, -5.4328999519348145, -5.594699859619141, -5.5507001876831055, -5.548600196838379]}, \"token.table\": {\"Topic\": [3, 1, 3, 4, 2, 1, 1, 2, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 3, 1, 1, 2, 3, 4, 1, 3, 2, 1, 1, 1, 2, 3, 4, 1, 2, 3, 1, 3, 2, 1, 2, 3, 4, 2, 2, 3, 1, 2, 4, 2, 2, 4, 4, 4, 2, 4, 1, 4, 1, 4, 3, 4, 4, 1, 2, 3, 4, 2, 3, 4, 1, 3, 2, 4, 3, 1, 2, 3, 4, 1, 2, 3, 4, 1, 4, 2, 4, 4, 2, 1, 2, 4, 4, 1, 2, 3, 3, 2, 4, 1, 3, 4, 1, 1, 3, 4, 2, 4, 4, 1, 1, 2, 3, 4, 1, 2, 3, 4, 2, 3, 1, 2, 4, 1, 3, 1, 3, 2, 3, 1, 4, 2, 2, 1, 4, 2, 1, 2, 3, 4, 3, 3, 3, 2, 1, 2, 3, 4, 1, 2, 3, 4, 1, 1, 4, 4, 4, 4, 2, 3, 1, 1, 2, 3, 4, 2, 4, 1, 3, 4, 1, 1, 2, 3, 4, 1, 4, 4, 2, 4, 2, 1, 2, 4, 2, 1, 1, 2, 3, 4, 1, 2, 3, 4, 4, 2, 3, 1, 4, 2, 3, 3, 3, 1, 2, 3, 4, 2, 1, 2, 3, 4, 4, 2, 3, 1, 4, 1, 1, 3, 4, 1, 4, 1, 1, 2, 3, 4, 1, 2, 3, 4, 3, 2, 3, 1, 2, 3, 4, 1, 3, 2, 1, 2, 3, 4, 2, 1, 2, 4, 1, 2, 3, 4, 2, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 4, 1, 4, 1, 1, 3, 4, 1, 2, 3, 4, 3, 1, 4, 3, 4, 1, 4, 4, 1, 2, 3, 1, 2, 3, 4, 1, 1, 1, 1, 2, 4, 3, 1, 4, 1, 2, 1, 2, 3, 4, 2, 4, 4, 4, 3, 4, 3, 2, 1, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 2, 3, 4, 2, 4, 1, 3, 4, 1, 4, 1, 2, 3, 1, 2, 3, 4, 1, 3, 4, 1, 2, 3, 4, 2, 3, 3, 1, 2, 3, 3, 2, 1, 2, 3, 4, 1, 1, 2, 3, 4, 1, 4, 2, 4, 2, 1, 2, 4, 3, 3, 3, 1, 2, 1, 4], \"Freq\": [0.9971605539321899, 0.9903265833854675, 0.9947761297225952, 0.9905667901039124, 0.9960644841194153, 0.9983757138252258, 0.6013520359992981, 0.228435680270195, 0.17010648548603058, 0.371998131275177, 0.1700294464826584, 0.21981707215309143, 0.2386048585176468, 0.24914690852165222, 0.0576728954911232, 0.08074205368757248, 0.6113327145576477, 0.13410015404224396, 0.6426079273223877, 0.13517296314239502, 0.08850610256195068, 0.9983764886856079, 0.9979061484336853, 0.047748032957315445, 0.5013543367385864, 0.3199118375778198, 0.1301133930683136, 0.16734378039836884, 0.8281371593475342, 0.9870674014091492, 0.9964740872383118, 0.9968286752700806, 0.2375430315732956, 0.421712189912796, 0.17243865132331848, 0.167746439576149, 0.9954916834831238, 0.9734445214271545, 0.024960115551948547, 0.9988813400268555, 0.9959440231323242, 0.9911641478538513, 0.7019439935684204, 0.08168578892946243, 0.0138450488448143, 0.20213772356510162, 0.9944295287132263, 0.9929133653640747, 0.9957379102706909, 0.5055922269821167, 0.4346930682659149, 0.05927632749080658, 0.9964970946311951, 0.8928671479225159, 0.1071440577507019, 0.9957683682441711, 0.990852952003479, 0.9923341274261475, 0.9914616942405701, 0.6787611246109009, 0.3205260634422302, 0.5573572516441345, 0.44220077991485596, 0.996955931186676, 0.995576798915863, 0.9978477954864502, 0.0479109063744545, 0.5850841999053955, 0.1250125616788864, 0.24177557229995728, 0.586305558681488, 0.23344889283180237, 0.17978248000144958, 0.8649564385414124, 0.13461242616176605, 0.11051678657531738, 0.8841342926025391, 0.9986643195152283, 0.1292707920074463, 0.5438288450241089, 0.16604609787464142, 0.16158847510814667, 0.17901581525802612, 0.31167930364608765, 0.45073622465133667, 0.059139151126146317, 0.17126664519309998, 0.8272501826286316, 0.19968612492084503, 0.7987444996833801, 0.9935455918312073, 0.9846317172050476, 0.16755442321300507, 0.615835964679718, 0.21605701744556427, 0.9967097043991089, 0.21673506498336792, 0.1825137436389923, 0.5988731980323792, 0.9920116662979126, 0.9968145489692688, 0.9921310544013977, 0.08659522980451584, 0.8734822869300842, 0.04141511023044586, 0.9964998960494995, 0.44462332129478455, 0.10677334666252136, 0.4478105902671814, 0.2388773113489151, 0.7606801986694336, 0.9990739226341248, 0.9933927655220032, 0.9907949566841125, 0.3200052082538605, 0.4377921521663666, 0.2418280392885208, 0.5032896399497986, 0.09655436128377914, 0.18948793411254883, 0.2100057452917099, 0.9927799701690674, 0.9949240684509277, 0.7064245343208313, 0.08250213414430618, 0.21083877980709076, 0.08971104770898819, 0.9120623469352722, 0.9965212345123291, 0.9968914985656738, 0.9958454370498657, 0.9925297498703003, 0.7438890337944031, 0.25555020570755005, 0.9988217353820801, 0.9955926537513733, 0.7332843542098999, 0.26449310779571533, 0.9960048198699951, 0.08951332420110703, 0.21193595230579376, 0.18034301698207855, 0.5173343420028687, 0.9971859455108643, 0.9992589950561523, 0.9958782196044922, 0.9991812705993652, 0.33904528617858887, 0.12933950126171112, 0.4533161222934723, 0.07659912109375, 0.050892505794763565, 0.17022666335105896, 0.6826615333557129, 0.09476535767316818, 0.995835542678833, 0.382500022649765, 0.6171543002128601, 0.9991904497146606, 0.9969090819358826, 0.9929643273353577, 0.9992761015892029, 0.9969155788421631, 0.9971583485603333, 0.47352269291877747, 0.34605833888053894, 0.17376172542572021, 0.006739493925124407, 0.8788086771965027, 0.1192074865102768, 0.28501856327056885, 0.09203724563121796, 0.6224884390830994, 0.9984647035598755, 0.07224497199058533, 0.06398840248584747, 0.13210508227348328, 0.7307062745094299, 0.8415530920028687, 0.15681113302707672, 0.993652880191803, 0.9966233372688293, 0.9989098310470581, 0.9909245371818542, 0.21399135887622833, 0.10039100795984268, 0.6842439770698547, 0.9875516295433044, 0.99235999584198, 0.15578214824199677, 0.36422303318977356, 0.11127296090126038, 0.36892470717430115, 0.010689569637179375, 0.632123589515686, 0.31328660249710083, 0.04399168863892555, 0.9977338314056396, 0.9911641478538513, 0.9985684156417847, 0.3093445897102356, 0.6904571652412415, 0.14808739721775055, 0.8520042300224304, 0.999485433101654, 0.9952287077903748, 0.3460911214351654, 0.3617476224899292, 0.1887020617723465, 0.10300330817699432, 0.9971777200698853, 0.32553327083587646, 0.16574770212173462, 0.0584290474653244, 0.4507383704185486, 0.9967706203460693, 0.07046496123075485, 0.9284794926643372, 0.8551024794578552, 0.14344856142997742, 0.9971003532409668, 0.8952444195747375, 0.007818728685379028, 0.09643098711967468, 0.7318074703216553, 0.2678062319755554, 0.9970114827156067, 0.3550889790058136, 0.2835152745246887, 0.1181313619017601, 0.24321162700653076, 0.2121962606906891, 0.47918498516082764, 0.0846792608499527, 0.22415098547935486, 0.9926247596740723, 0.9912770986557007, 0.9944939017295837, 0.3245641887187958, 0.2186010628938675, 0.27033108472824097, 0.18606121838092804, 0.9978359341621399, 0.9936323761940002, 0.9971758127212524, 0.24445414543151855, 0.5272281169891357, 0.17970682680606842, 0.04889082908630371, 0.9970647096633911, 0.5279070734977722, 0.20958109200000763, 0.26230588555336, 0.12195933610200882, 0.7564073801040649, 0.1206618919968605, 0.9975947141647339, 0.9955248236656189, 0.17781487107276917, 0.40588176250457764, 0.20358514785766602, 0.21260473132133484, 0.11345221847295761, 0.4435879588127136, 0.14309288561344147, 0.30049505829811096, 0.5048519372940063, 0.2339235246181488, 0.047577667981386185, 0.21409949660301208, 0.9968568682670593, 0.9933684468269348, 0.040441058576107025, 0.95903080701828, 0.9942945837974548, 0.6352203488349915, 0.04394606128334999, 0.3196077346801758, 0.10652483254671097, 0.645201563835144, 0.08110413700342178, 0.167050302028656, 0.9969222545623779, 0.9932383894920349, 0.9979149103164673, 0.995437502861023, 0.9981278777122498, 0.9993108510971069, 0.9978463649749756, 0.9962404370307922, 0.9972676038742065, 0.3065307140350342, 0.6926414966583252, 0.39754700660705566, 0.1726953387260437, 0.1802290380001068, 0.2491912692785263, 0.9978943467140198, 0.994848906993866, 0.9969589114189148, 0.34266531467437744, 0.22160392999649048, 0.43500030040740967, 0.9945238828659058, 0.7926304936408997, 0.20653992891311646, 0.9896805882453918, 0.9901014566421509, 0.37549591064453125, 0.21267807483673096, 0.19635215401649475, 0.2153255194425583, 0.8514540791511536, 0.1460653394460678, 0.9984861612319946, 0.9955447912216187, 0.9973504543304443, 0.9980834126472473, 0.9912415742874146, 0.9955049157142639, 0.9965306520462036, 0.992300271987915, 0.15920385718345642, 0.48931774497032166, 0.3308942914009094, 0.020290687680244446, 0.12216336280107498, 0.15881237387657166, 0.051308609545230865, 0.6670119166374207, 0.7565540075302124, 0.24180997908115387, 0.7270925045013428, 0.06659352034330368, 0.20657582581043243, 0.8112483024597168, 0.18929126858711243, 0.586029589176178, 0.18462030589580536, 0.22797809541225433, 0.99614417552948, 0.9935050010681152, 0.13294316828250885, 0.22209328413009644, 0.6443833112716675, 0.10462000966072083, 0.3335611820220947, 0.5468773245811462, 0.01494571566581726, 0.05977186560630798, 0.9384182691574097, 0.994836688041687, 0.4299854338169098, 0.21187688410282135, 0.23472633957862854, 0.1232486441731453, 0.9925218820571899, 0.9967215657234192, 0.9968281388282776, 0.12196741998195648, 0.22457493841648102, 0.6533969044685364, 0.9896941781044006, 0.996309757232666, 0.32636430859565735, 0.24138301610946655, 0.28116148710250854, 0.15097738802433014, 0.9932385087013245, 0.15509141981601715, 0.3556663691997528, 0.2967614531517029, 0.19237300753593445, 0.7899529337882996, 0.20854757726192474, 0.7889741659164429, 0.2102964222431183, 0.9984651207923889, 0.04986218363046646, 0.26064324378967285, 0.6890047192573547, 0.9973514676094055, 0.9976268410682678, 0.997096836566925, 0.17901010811328888, 0.8194684982299805, 0.996753454208374, 0.9983729124069214], \"Term\": [\"activation\", \"active\", \"activity\", \"additive\", \"affinity\", \"agent\", \"algorithm\", \"algorithm\", \"algorithm\", \"also\", \"also\", \"also\", \"also\", \"analysis\", \"analysis\", \"analysis\", \"analysis\", \"approach\", \"approach\", \"approach\", \"approach\", \"architecture\", \"arm\", \"art\", \"art\", \"art\", \"art\", \"attention\", \"attention\", \"attribute\", \"b\", \"bandit\", \"based\", \"based\", \"based\", \"based\", \"batch\", \"bayesian\", \"bayesian\", \"bound\", \"brain\", \"carlo\", \"case\", \"case\", \"case\", \"case\", \"causal\", \"chain\", \"cifar\", \"class\", \"class\", \"class\", \"cluster\", \"clustering\", \"clustering\", \"coefficient\", \"column\", \"community\", \"completion\", \"convergence\", \"convergence\", \"convex\", \"convex\", \"convolutional\", \"coordinate\", \"covariance\", \"data\", \"data\", \"data\", \"data\", \"datasets\", \"datasets\", \"datasets\", \"decision\", \"decision\", \"decomposition\", \"decomposition\", \"deep\", \"demonstrate\", \"demonstrate\", \"demonstrate\", \"demonstrate\", \"different\", \"different\", \"different\", \"different\", \"dimension\", \"dimension\", \"dimensional\", \"dimensional\", \"dimensionality\", \"discovery\", \"distribution\", \"distribution\", \"distribution\", \"divergence\", \"dynamic\", \"dynamic\", \"dynamic\", \"dynamical\", \"edge\", \"ell_\", \"end\", \"end\", \"end\", \"epsilon\", \"error\", \"error\", \"error\", \"estimation\", \"estimation\", \"estimator\", \"expected\", \"exploration\", \"feature\", \"feature\", \"feature\", \"first\", \"first\", \"first\", \"first\", \"flexibility\", \"frame\", \"function\", \"function\", \"function\", \"future\", \"future\", \"game\", \"gan\", \"generating\", \"generator\", \"gradient\", \"gradient\", \"graph\", \"graphical\", \"guarantee\", \"guarantee\", \"hash\", \"high\", \"high\", \"high\", \"high\", \"human\", \"image\", \"imagenet\", \"inference\", \"information\", \"information\", \"information\", \"information\", \"input\", \"input\", \"input\", \"input\", \"item\", \"k\", \"k\", \"kernel\", \"l\", \"lasso\", \"latent\", \"layer\", \"learner\", \"learning\", \"learning\", \"learning\", \"learning\", \"likelihood\", \"likelihood\", \"linear\", \"linear\", \"linear\", \"loss\", \"low\", \"low\", \"low\", \"low\", \"lower\", \"lower\", \"manifold\", \"marginal\", \"matrix\", \"mcmc\", \"mean\", \"mean\", \"mean\", \"message\", \"meta\", \"method\", \"method\", \"method\", \"method\", \"model\", \"model\", \"model\", \"model\", \"moment\", \"monte\", \"motion\", \"n\", \"n\", \"network\", \"network\", \"neural\", \"neuron\", \"new\", \"new\", \"new\", \"new\", \"node\", \"non\", \"non\", \"non\", \"non\", \"norm\", \"object\", \"object\", \"objective\", \"objective\", \"online\", \"optimal\", \"optimal\", \"optimal\", \"optimization\", \"optimization\", \"oracle\", \"paper\", \"paper\", \"paper\", \"paper\", \"parameter\", \"parameter\", \"parameter\", \"parameter\", \"parsing\", \"partition\", \"pattern\", \"performance\", \"performance\", \"performance\", \"performance\", \"policy\", \"population\", \"posterior\", \"present\", \"present\", \"present\", \"present\", \"probabilistic\", \"problem\", \"problem\", \"problem\", \"process\", \"process\", \"process\", \"projection\", \"propagation\", \"propose\", \"propose\", \"propose\", \"propose\", \"proposed\", \"proposed\", \"proposed\", \"proposed\", \"provide\", \"provide\", \"provide\", \"provide\", \"query\", \"r\", \"rank\", \"rank\", \"ranking\", \"rate\", \"rate\", \"rate\", \"real\", \"real\", \"real\", \"real\", \"recognition\", \"recommendation\", \"recovery\", \"recurrent\", \"regression\", \"regret\", \"regularization\", \"regularized\", \"reinforcement\", \"representation\", \"representation\", \"result\", \"result\", \"result\", \"result\", \"reward\", \"risk\", \"rl\", \"sample\", \"sample\", \"sample\", \"scene\", \"setting\", \"setting\", \"sgd\", \"shot\", \"show\", \"show\", \"show\", \"show\", \"similarity\", \"similarity\", \"sparse\", \"sparsity\", \"spatial\", \"spectral\", \"spike\", \"spns\", \"sqrt\", \"square\", \"state\", \"state\", \"state\", \"state\", \"statistical\", \"statistical\", \"statistical\", \"statistical\", \"stochastic\", \"stochastic\", \"structure\", \"structure\", \"structure\", \"structured\", \"structured\", \"study\", \"study\", \"study\", \"submodular\", \"subspace\", \"system\", \"system\", \"system\", \"task\", \"task\", \"task\", \"task\", \"temporal\", \"temporal\", \"tensor\", \"time\", \"time\", \"time\", \"time\", \"topic\", \"train\", \"trained\", \"training\", \"training\", \"training\", \"translation\", \"tree\", \"two\", \"two\", \"two\", \"two\", \"upper\", \"using\", \"using\", \"using\", \"using\", \"value\", \"value\", \"variable\", \"variable\", \"variational\", \"vector\", \"vector\", \"vector\", \"video\", \"visual\", \"word\", \"world\", \"world\", \"worst\", \"x\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [4, 2, 3, 1]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el141221402019799297281769053404\", ldavis_el141221402019799297281769053404_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el141221402019799297281769053404\", ldavis_el141221402019799297281769053404_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el141221402019799297281769053404\", ldavis_el141221402019799297281769053404_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "PreparedData(topic_coordinates=              x         y  topics  cluster       Freq\n",
       "topic                                                \n",
       "3      0.096551  0.119806       1        1  29.222599\n",
       "1     -0.033844 -0.159776       2        1  27.591478\n",
       "2     -0.232030  0.059157       3        1  22.493319\n",
       "0      0.169324 -0.019186       4        1  20.692600, topic_info=     Category         Freq           Term        Total  loglift  logprob\n",
       "term                                                                    \n",
       "785   Default  2491.000000        network  2491.000000  30.0000  30.0000\n",
       "156   Default  4864.000000          model  4864.000000  29.0000  29.0000\n",
       "80    Default  1214.000000         neural  1214.000000  28.0000  28.0000\n",
       "323   Default  1106.000000          image  1106.000000  27.0000  27.0000\n",
       "27    Default  1027.000000         matrix  1027.000000  26.0000  26.0000\n",
       "0     Default  4097.000000      algorithm  4097.000000  25.0000  25.0000\n",
       "560   Default  1067.000000          bound  1067.000000  24.0000  24.0000\n",
       "974   Default   876.000000           deep   876.000000  23.0000  23.0000\n",
       "146   Default   924.000000      inference   924.000000  22.0000  22.0000\n",
       "540   Default   725.000000         kernel   725.000000  21.0000  21.0000\n",
       "595   Default   871.000000          graph   871.000000  20.0000  20.0000\n",
       "482   Default  3034.000000        problem  3034.000000  19.0000  19.0000\n",
       "8     Default  3151.000000           data  3151.000000  18.0000  18.0000\n",
       "633   Default   562.000000      estimator   562.000000  17.0000  17.0000\n",
       "407   Default  1745.000000       function  1745.000000  16.0000  16.0000\n",
       "486   Default   497.000000         sparse   497.000000  15.0000  15.0000\n",
       "1135  Default   605.000000         latent   605.000000  14.0000  14.0000\n",
       "603   Default   808.000000              n   808.000000  13.0000  13.0000\n",
       "155   Default  3412.000000       learning  3412.000000  12.0000  12.0000\n",
       "221   Default  1019.000000   optimization  1019.000000  11.0000  11.0000\n",
       "755   Default   445.000000     regression   445.000000  10.0000  10.0000\n",
       "22    Default   966.000000       gradient   966.000000   9.0000   9.0000\n",
       "77    Default  1010.000000         linear  1010.000000   8.0000   8.0000\n",
       "233   Default  1471.000000           task  1471.000000   7.0000   7.0000\n",
       "875   Default   444.000000   architecture   444.000000   6.0000   6.0000\n",
       "1032  Default   560.000000       bayesian   560.000000   5.0000   5.0000\n",
       "234   Default  1033.000000       training  1033.000000   4.0000   4.0000\n",
       "786   Default   767.000000        optimal   767.000000   3.0000   3.0000\n",
       "1714  Default   524.000000           loss   524.000000   2.0000   2.0000\n",
       "291   Default   406.000000              x   406.000000   1.0000   1.0000\n",
       "...       ...          ...            ...          ...      ...      ...\n",
       "4718   Topic4    92.071892     completion    92.792290   1.5676  -6.7106\n",
       "2493   Topic4   331.801910           rank   346.182831   1.5330  -5.4286\n",
       "631    Topic4   427.881348    dimensional   535.840942   1.3504  -5.1743\n",
       "465    Topic4   448.968414     estimation   590.261169   1.3018  -5.1262\n",
       "690    Topic4   255.972748      dimension   309.458984   1.3856  -5.6881\n",
       "603    Topic4   557.567871              n   808.160217   1.2042  -4.9095\n",
       "9      Topic4   168.094971  decomposition   190.016388   1.4528  -6.1086\n",
       "330    Topic4   354.418732            low   484.462799   1.2628  -5.3627\n",
       "77     Topic4   629.499146         linear  1010.460510   1.1022  -4.7882\n",
       "57     Topic4   530.407288       analysis   866.958374   1.0840  -4.9595\n",
       "539    Topic4   455.221680              k   737.254883   1.0932  -5.1123\n",
       "844    Topic4   304.020996         vector   441.216125   1.2030  -5.5160\n",
       "78     Topic4  1176.537354         method  3190.352783   0.5778  -4.1628\n",
       "441    Topic4   273.308380    statistical   409.288025   1.1716  -5.6225\n",
       "542    Topic4   259.436951           mean   378.519958   1.1976  -5.6746\n",
       "320    Topic4   393.357849           high   759.663452   0.9172  -5.2584\n",
       "482    Topic4   796.346497        problem  3034.625000   0.2376  -4.5531\n",
       "170    Topic4   424.227417         sample   974.711975   0.7435  -5.1829\n",
       "8      Topic4   761.516479           data  3151.683105   0.1550  -4.5978\n",
       "37     Topic4   377.656586            non   838.623962   0.7776  -5.2991\n",
       "0      Topic4   697.412476      algorithm  4097.433594  -0.1953  -4.6858\n",
       "121    Topic4   487.750336           show  2266.336182   0.0393  -5.0433\n",
       "227    Topic4   429.764740         result  1725.582153   0.1853  -5.1699\n",
       "407    Topic4   368.460938       function  1745.409424   0.0200  -5.3238\n",
       "222    Topic4   350.078674          paper  1439.075928   0.1618  -5.3750\n",
       "525    Topic4   287.549072         convex   651.287842   0.7578  -5.5717\n",
       "547    Topic4   330.387543        propose  1552.176147   0.0282  -5.4329\n",
       "16     Topic4   281.012909          error   627.497437   0.7721  -5.5947\n",
       "275    Topic4   293.657166       proposed   978.385437   0.3719  -5.5507\n",
       "137    Topic4   294.267548   distribution  1360.751953   0.0441  -5.5486\n",
       "\n",
       "[270 rows x 6 columns], token_table=      Topic      Freq          Term\n",
       "term                               \n",
       "872       3  0.997161    activation\n",
       "1064      1  0.990327        active\n",
       "375       3  0.994776      activity\n",
       "931       4  0.990567      additive\n",
       "5229      2  0.996064      affinity\n",
       "1953      1  0.998376         agent\n",
       "0         1  0.601352     algorithm\n",
       "0         2  0.228436     algorithm\n",
       "0         4  0.170106     algorithm\n",
       "1         1  0.371998          also\n",
       "1         2  0.170029          also\n",
       "1         3  0.219817          also\n",
       "1         4  0.238605          also\n",
       "57        1  0.249147      analysis\n",
       "57        2  0.057673      analysis\n",
       "57        3  0.080742      analysis\n",
       "57        4  0.611333      analysis\n",
       "126       1  0.134100      approach\n",
       "126       2  0.642608      approach\n",
       "126       3  0.135173      approach\n",
       "126       4  0.088506      approach\n",
       "875       3  0.998376  architecture\n",
       "2677      1  0.997906           arm\n",
       "1408      1  0.047748           art\n",
       "1408      2  0.501354           art\n",
       "1408      3  0.319912           art\n",
       "1408      4  0.130113           art\n",
       "1757      1  0.167344     attention\n",
       "1757      3  0.828137     attention\n",
       "1727      2  0.987067     attribute\n",
       "...     ...       ...           ...\n",
       "965       3  0.996828       trained\n",
       "234       1  0.121967      training\n",
       "234       2  0.224575      training\n",
       "234       3  0.653397      training\n",
       "2084      3  0.989694   translation\n",
       "182       2  0.996310          tree\n",
       "52        1  0.326364           two\n",
       "52        2  0.241383           two\n",
       "52        3  0.281161           two\n",
       "52        4  0.150977           two\n",
       "869       1  0.993239         upper\n",
       "56        1  0.155091         using\n",
       "56        2  0.355666         using\n",
       "56        3  0.296761         using\n",
       "56        4  0.192373         using\n",
       "1094      1  0.789953         value\n",
       "1094      4  0.208548         value\n",
       "188       2  0.788974      variable\n",
       "188       4  0.210296      variable\n",
       "1590      2  0.998465   variational\n",
       "844       1  0.049862        vector\n",
       "844       2  0.260643        vector\n",
       "844       4  0.689005        vector\n",
       "1158      3  0.997351         video\n",
       "371       3  0.997627        visual\n",
       "452       3  0.997097          word\n",
       "190       1  0.179010         world\n",
       "190       2  0.819468         world\n",
       "1973      1  0.996753         worst\n",
       "291       4  0.998373             x\n",
       "\n",
       "[388 rows x 3 columns], R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[4, 2, 3, 1])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pyLDAvis.enable_notebook()\n",
    "pyLDAvis.gensim.prepare(lda_model, word_map, dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = lda_model.show_topics(formatted=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0\n",
      "['method', 'matrix', 'problem', 'data', 'kernel', 'algorithm', 'linear', 'estimator', 'n', 'analysis']\n",
      "Topic 1\n",
      "['model', 'data', 'approach', 'learning', 'method', 'algorithm', 'inference', 'graph', 'distribution', 'based']\n",
      "Topic 2\n",
      "['network', 'model', 'neural', 'image', 'deep', 'task', 'training', 'learning', 'representation', 'object']\n",
      "Topic 3\n",
      "['algorithm', 'learning', 'problem', 'function', 'bound', 'show', 'optimization', 'gradient', 'optimal', 'result']\n"
     ]
    }
   ],
   "source": [
    "topix={}\n",
    "for i in range(len(topics)):\n",
    "    val=[]\n",
    "    print( 'Topic '+str(i))\n",
    "    for j in range(len(topics[i][1])):\n",
    "        val.append(topics[i][1][j][0])\n",
    "    print(val)\n",
    "    topix['Topic '+str(i)]=val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12641"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#len(lda_model[word_map])\n",
    "len(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=LatentDirichletAllocation(batch_size=128, doc_topic_prior=None,\n",
       "             evaluate_every=-1, learning_decay=0.7,\n",
       "             learning_method='online', learning_offset=10.0,\n",
       "             max_doc_update_iter=100, max_iter=10, mean_change_tol=0.001,\n",
       "             n_components=10, n_jobs=1, n_topics=None, perp_tol=0.1,\n",
       "             random_state=None, topic_word_prior=None,\n",
       "             total_samples=1000000.0, verbose=0),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'n_components': [4, 5, 6], 'learning_decay': [0.5, 0.7, 0.9]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_feat =5000\n",
    "# LDA can only use raw term counts  because it is a probabilistic graphical model\n",
    "tf_vectorizer = CountVectorizer(max_features=no_feat,stop_words='english')\n",
    "X_tf = tf_vectorizer.fit_transform(data_df['abstract_post'])\n",
    "tf_feat_name = tf_vectorizer.get_feature_names()\n",
    "\n",
    "lda = LatentDirichletAllocation(learning_method='online')\n",
    "lda_param = {'n_components': [4,5,6], 'learning_decay': [0.5,0.7,0.9]}\n",
    "lda_model = GridSearchCV(estimator=lda,param_grid=lda_param)\n",
    "lda_model.fit(X_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_decay': 0.9, 'n_components': 4}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_lda_model =lda_model.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_output = best_lda_model.fit_transform(X_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2855, 2973, 2975, 2147, 2526, 4534, 3045, 1146, 4331, 1747])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argsort(best_lda_model.components_[1])[:-10-1:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualizing_topic_cluster(model,stop_len,feat_name):\n",
    "    topic={}\n",
    "    for index,topix in enumerate(model.components_):\n",
    "        topic[index]= [feat_name[i] for i in topix.argsort()[:-stop_len-1:-1]]\n",
    "    \n",
    "    return topic\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_topic=visualizing_topic_cluster(best_lda_model,stop_len=10,feat_name=tf_feat_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(best_lda_model.components_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic0 ['method', 'data', 'problem', 'algorithm', 'learning', 'model', 'matrix', 'approach', 'function', 'kernel']\n",
      "Topic1 ['model', 'network', 'neural', 'image', 'learning', 'task', 'object', 'deep', 'state', 'feature']\n",
      "Topic2 ['model', 'data', 'inference', 'learning', 'distribution', 'latent', 'label', 'approach', 'method', 'variable']\n",
      "Topic3 ['algorithm', 'problem', 'learning', 'function', 'bound', 'optimal', 'result', 'time', 'policy', 'stochastic']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([print('Topic'+str(key),dict_topic[key]) for key in dict_topic])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns=['Topic'+ i for i in list(map(str,list(dict_topic.keys())))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_df = pd.concat(objs=[data_df,pd.DataFrame(lda_output,columns=columns).apply(lambda x : np.round(x,2)),pd.DataFrame([[np.argmax(x),dict_topic[np.argmax(x)]] for x in lda_output],columns=['Major_topic','keywords'])],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Topic0', 'Topic1', 'Topic2', 'Topic3']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse_calculation(x,y):\n",
    "    x,y =x,y\n",
    "    error=[]\n",
    "    len_y =len(y)\n",
    "    for i in range(len_y):\n",
    "        error.append(np.sqrt(np.power((np.array(x)-np.array(y[i])),2).sum()))\n",
    "    return error "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reccomendation(df,paper_id,col):\n",
    "    paper_1 = df[(df['id']==paper_id)]\n",
    "    dominant_topic = int(paper_1['Major_topic'])\n",
    "    paper_2 = df[(df['Major_topic']== dominant_topic)]\n",
    "    paper_2 = paper_2.drop(paper_1.index)\n",
    "    x= paper_1[columns].values.tolist()\n",
    "    y= paper_2[columns].values.tolist()\n",
    "    error = np.round(rmse_calculation(x,y),2)\n",
    "    paper_2['error'] = error\n",
    "    return  paper_2[['id','title','error']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>year</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>abstract_post</th>\n",
       "      <th>word_count_pre</th>\n",
       "      <th>word_count_post</th>\n",
       "      <th>Topic0</th>\n",
       "      <th>Topic1</th>\n",
       "      <th>Topic2</th>\n",
       "      <th>Topic3</th>\n",
       "      <th>Major_topic</th>\n",
       "      <th>keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1861</td>\n",
       "      <td>2000</td>\n",
       "      <td>Algorithms for Non-negative Matrix Factorization</td>\n",
       "      <td>non negative matrix factorization nmf has prev...</td>\n",
       "      <td>non negative matrix factorization nmf previous...</td>\n",
       "      <td>108</td>\n",
       "      <td>67</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.61</td>\n",
       "      <td>3</td>\n",
       "      <td>[algorithm, problem, learning, function, bound...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1975</td>\n",
       "      <td>2001</td>\n",
       "      <td>Characterizing Neural Gain Control using Spike...</td>\n",
       "      <td>spike triggered averaging techniques are effec...</td>\n",
       "      <td>spike triggered averaging technique effective ...</td>\n",
       "      <td>83</td>\n",
       "      <td>52</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "      <td>[model, network, neural, image, learning, task...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3163</td>\n",
       "      <td>2007</td>\n",
       "      <td>Competition Adds Complexity</td>\n",
       "      <td>it is known that determinining whether a dec p...</td>\n",
       "      <td>known determinining whether dec pomdp namely c...</td>\n",
       "      <td>70</td>\n",
       "      <td>40</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.97</td>\n",
       "      <td>3</td>\n",
       "      <td>[algorithm, problem, learning, function, bound...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3164</td>\n",
       "      <td>2007</td>\n",
       "      <td>Efficient Principled Learning of Thin Junction...</td>\n",
       "      <td>we present the first truly polynomial algorith...</td>\n",
       "      <td>present first truly polynomial algorithm learn...</td>\n",
       "      <td>144</td>\n",
       "      <td>89</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0</td>\n",
       "      <td>[method, data, problem, algorithm, learning, m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3167</td>\n",
       "      <td>2007</td>\n",
       "      <td>Regularized Boost for Semi-Supervised Learning</td>\n",
       "      <td>semi supervised inductive learning concerns ho...</td>\n",
       "      <td>semi supervised inductive learning concern lea...</td>\n",
       "      <td>123</td>\n",
       "      <td>81</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>[method, data, problem, algorithm, learning, m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3168</td>\n",
       "      <td>2007</td>\n",
       "      <td>Simplified Rules and Theoretical Analysis for ...</td>\n",
       "      <td>we show that under suitable assumptions primar...</td>\n",
       "      <td>show suitable assumption primarily linearizati...</td>\n",
       "      <td>158</td>\n",
       "      <td>99</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>[model, network, neural, image, learning, task...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3169</td>\n",
       "      <td>2007</td>\n",
       "      <td>Predicting human gaze using low-level saliency...</td>\n",
       "      <td>under natural viewing conditions human observe...</td>\n",
       "      <td>natural viewing condition human observer shift...</td>\n",
       "      <td>204</td>\n",
       "      <td>129</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>[model, network, neural, image, learning, task...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3171</td>\n",
       "      <td>2007</td>\n",
       "      <td>Mining Internet-Scale Software Repositories</td>\n",
       "      <td>large repositories of source code create new c...</td>\n",
       "      <td>large repository source code create new challe...</td>\n",
       "      <td>191</td>\n",
       "      <td>130</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>[model, data, inference, learning, distributio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3172</td>\n",
       "      <td>2007</td>\n",
       "      <td>Continuous Time Particle Filtering for fMRI</td>\n",
       "      <td>we construct a biologically motivated stochast...</td>\n",
       "      <td>construct biologically motivated stochastic di...</td>\n",
       "      <td>102</td>\n",
       "      <td>63</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>[method, data, problem, algorithm, learning, m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3174</td>\n",
       "      <td>2007</td>\n",
       "      <td>An online Hebbian learning rule that performs ...</td>\n",
       "      <td>independent component analysis ica is a powerf...</td>\n",
       "      <td>independent component analysis ica powerful me...</td>\n",
       "      <td>104</td>\n",
       "      <td>62</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>[method, data, problem, algorithm, learning, m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3176</td>\n",
       "      <td>2007</td>\n",
       "      <td>Discriminative K-means for Clustering</td>\n",
       "      <td>we present a theoretical study on the discrimi...</td>\n",
       "      <td>present theoretical study discriminative clust...</td>\n",
       "      <td>191</td>\n",
       "      <td>117</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>[method, data, problem, algorithm, learning, m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3178</td>\n",
       "      <td>2007</td>\n",
       "      <td>The Epoch-Greedy Algorithm for Multi-armed Ban...</td>\n",
       "      <td>we present epoch greedy an algorithm for multi...</td>\n",
       "      <td>present epoch greedy algorithm multi armed ban...</td>\n",
       "      <td>73</td>\n",
       "      <td>42</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.98</td>\n",
       "      <td>3</td>\n",
       "      <td>[algorithm, problem, learning, function, bound...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3186</td>\n",
       "      <td>2007</td>\n",
       "      <td>Local Algorithms for Approximate Inference in ...</td>\n",
       "      <td>we present a new local approximation algorithm...</td>\n",
       "      <td>present new local approximation algorithm comp...</td>\n",
       "      <td>172</td>\n",
       "      <td>107</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>3</td>\n",
       "      <td>[algorithm, problem, learning, function, bound...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3188</td>\n",
       "      <td>2007</td>\n",
       "      <td>Catching Change-points with Lasso</td>\n",
       "      <td>we propose a new approach for dealing with the...</td>\n",
       "      <td>propose new approach dealing estimation locati...</td>\n",
       "      <td>103</td>\n",
       "      <td>58</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>[method, data, problem, algorithm, learning, m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3190</td>\n",
       "      <td>2007</td>\n",
       "      <td>Evaluating Search Engines by Modeling the Rela...</td>\n",
       "      <td>we propose a model that leverages the millions...</td>\n",
       "      <td>propose model leverage million click received ...</td>\n",
       "      <td>214</td>\n",
       "      <td>115</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0</td>\n",
       "      <td>[method, data, problem, algorithm, learning, m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3191</td>\n",
       "      <td>2007</td>\n",
       "      <td>Random Projections for Manifold Learning</td>\n",
       "      <td>we propose a novel method for em linear dimens...</td>\n",
       "      <td>propose novel method em linear dimensionality ...</td>\n",
       "      <td>143</td>\n",
       "      <td>88</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0</td>\n",
       "      <td>[method, data, problem, algorithm, learning, m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>3195</td>\n",
       "      <td>2007</td>\n",
       "      <td>Learning the structure of manifolds using rand...</td>\n",
       "      <td>we present a simple variant of the k d tree wh...</td>\n",
       "      <td>present simple variant k tree automatically ad...</td>\n",
       "      <td>20</td>\n",
       "      <td>12</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0</td>\n",
       "      <td>[method, data, problem, algorithm, learning, m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>3196</td>\n",
       "      <td>2007</td>\n",
       "      <td>A Probabilistic Approach to Language Change</td>\n",
       "      <td>we present a probabilistic approach to languag...</td>\n",
       "      <td>present probabilistic approach language change...</td>\n",
       "      <td>104</td>\n",
       "      <td>65</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>[model, data, inference, learning, distributio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>3197</td>\n",
       "      <td>2007</td>\n",
       "      <td>Online Linear Regression and Its Application t...</td>\n",
       "      <td>we provide a provably efficient algorithm for ...</td>\n",
       "      <td>provide provably efficient algorithm learning ...</td>\n",
       "      <td>87</td>\n",
       "      <td>55</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.98</td>\n",
       "      <td>3</td>\n",
       "      <td>[algorithm, problem, learning, function, bound...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>3199</td>\n",
       "      <td>2007</td>\n",
       "      <td>Scan Strategies for Meteorological Radars</td>\n",
       "      <td>we address the problem of adaptive sensor cont...</td>\n",
       "      <td>address problem adaptive sensor control dynami...</td>\n",
       "      <td>169</td>\n",
       "      <td>99</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.83</td>\n",
       "      <td>3</td>\n",
       "      <td>[algorithm, problem, learning, function, bound...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>3200</td>\n",
       "      <td>2007</td>\n",
       "      <td>Fixing Max-Product: Convergent Message Passing...</td>\n",
       "      <td>we present a novel message passing algorithm f...</td>\n",
       "      <td>present novel message passing algorithm approx...</td>\n",
       "      <td>104</td>\n",
       "      <td>62</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.70</td>\n",
       "      <td>3</td>\n",
       "      <td>[algorithm, problem, learning, function, bound...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>3202</td>\n",
       "      <td>2007</td>\n",
       "      <td>Parallelizing Support Vector Machines on Distr...</td>\n",
       "      <td>support vector machines svms suffer from a wid...</td>\n",
       "      <td>support vector machine svms suffer widely reco...</td>\n",
       "      <td>112</td>\n",
       "      <td>72</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0</td>\n",
       "      <td>[method, data, problem, algorithm, learning, m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>3203</td>\n",
       "      <td>2007</td>\n",
       "      <td>Predictive Matrix-Variate t Models</td>\n",
       "      <td>it is becoming increasingly important to learn...</td>\n",
       "      <td>becoming increasingly important learn partiall...</td>\n",
       "      <td>132</td>\n",
       "      <td>77</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>[model, data, inference, learning, distributio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>3204</td>\n",
       "      <td>2007</td>\n",
       "      <td>Modelling motion primitives and their timing i...</td>\n",
       "      <td>biological movement is built up of sub blocks ...</td>\n",
       "      <td>biological movement built sub block motion pri...</td>\n",
       "      <td>170</td>\n",
       "      <td>102</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>[model, network, neural, image, learning, task...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>3206</td>\n",
       "      <td>2007</td>\n",
       "      <td>Learning the 2-D Topology of Images</td>\n",
       "      <td>we study the following question is the two dim...</td>\n",
       "      <td>study following question two dimensional struc...</td>\n",
       "      <td>159</td>\n",
       "      <td>82</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>[model, network, neural, image, learning, task...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>3209</td>\n",
       "      <td>2007</td>\n",
       "      <td>On higher-order perceptron algorithms</td>\n",
       "      <td>a new algorithm for on line learning linear th...</td>\n",
       "      <td>new algorithm line learning linear threshold f...</td>\n",
       "      <td>103</td>\n",
       "      <td>68</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.54</td>\n",
       "      <td>3</td>\n",
       "      <td>[algorithm, problem, learning, function, bound...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>3210</td>\n",
       "      <td>2007</td>\n",
       "      <td>Configuration Estimates Improve Pedestrian Fin...</td>\n",
       "      <td>fair discriminative pedestrian finders are now...</td>\n",
       "      <td>fair discriminative pedestrian finder availabl...</td>\n",
       "      <td>116</td>\n",
       "      <td>70</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>[model, network, neural, image, learning, task...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>3211</td>\n",
       "      <td>2007</td>\n",
       "      <td>Using Deep Belief Nets to Learn Covariance Ker...</td>\n",
       "      <td>we show how to use unlabeled data and a deep b...</td>\n",
       "      <td>show use unlabeled data deep belief net dbn le...</td>\n",
       "      <td>102</td>\n",
       "      <td>61</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0</td>\n",
       "      <td>[method, data, problem, algorithm, learning, m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>3212</td>\n",
       "      <td>2007</td>\n",
       "      <td>Learning Bounds for Domain Adaptation</td>\n",
       "      <td>empirical risk minimization offers well known ...</td>\n",
       "      <td>empirical risk minimization offer well known l...</td>\n",
       "      <td>143</td>\n",
       "      <td>89</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.74</td>\n",
       "      <td>3</td>\n",
       "      <td>[algorithm, problem, learning, function, bound...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>3213</td>\n",
       "      <td>2007</td>\n",
       "      <td>Unconstrained On-line Handwriting Recognition ...</td>\n",
       "      <td>on line handwriting recognition is unusual amo...</td>\n",
       "      <td>line handwriting recognition unusual among seq...</td>\n",
       "      <td>128</td>\n",
       "      <td>80</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>[model, network, neural, image, learning, task...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3894</th>\n",
       "      <td>7255</td>\n",
       "      <td>2017</td>\n",
       "      <td>Attend and Predict: Understanding Gene Regulat...</td>\n",
       "      <td>the past decade has seen a revolution in genom...</td>\n",
       "      <td>past decade seen revolution genomic technology...</td>\n",
       "      <td>215</td>\n",
       "      <td>146</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>[model, network, neural, image, learning, task...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3895</th>\n",
       "      <td>7256</td>\n",
       "      <td>2017</td>\n",
       "      <td>Acceleration and Averaging in Stochastic Desce...</td>\n",
       "      <td>we formulate and study a general family of con...</td>\n",
       "      <td>formulate study general family continuous time...</td>\n",
       "      <td>134</td>\n",
       "      <td>76</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.88</td>\n",
       "      <td>3</td>\n",
       "      <td>[algorithm, problem, learning, function, bound...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3896</th>\n",
       "      <td>7257</td>\n",
       "      <td>2017</td>\n",
       "      <td>Kernel functions based on triplet comparisons</td>\n",
       "      <td>given only information in the form of similari...</td>\n",
       "      <td>given information form similarity triplet obje...</td>\n",
       "      <td>85</td>\n",
       "      <td>51</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0</td>\n",
       "      <td>[method, data, problem, algorithm, learning, m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3897</th>\n",
       "      <td>7258</td>\n",
       "      <td>2017</td>\n",
       "      <td>An Error Detection and Correction Framework fo...</td>\n",
       "      <td>we define and study error detection and correc...</td>\n",
       "      <td>define study error detection correction task u...</td>\n",
       "      <td>141</td>\n",
       "      <td>81</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>[model, network, neural, image, learning, task...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3898</th>\n",
       "      <td>7259</td>\n",
       "      <td>2017</td>\n",
       "      <td>Style Transfer from Non-Parallel Text by Cross...</td>\n",
       "      <td>this paper focuses on style transfer on the ba...</td>\n",
       "      <td>paper focus style transfer basis non parallel ...</td>\n",
       "      <td>111</td>\n",
       "      <td>68</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>[model, data, inference, learning, distributio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3899</th>\n",
       "      <td>7260</td>\n",
       "      <td>2017</td>\n",
       "      <td>Cross-Spectral Factor Analysis</td>\n",
       "      <td>in neuropsychiatric disorders such as schizoph...</td>\n",
       "      <td>neuropsychiatric disorder schizophrenia depres...</td>\n",
       "      <td>169</td>\n",
       "      <td>107</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>[model, network, neural, image, learning, task...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3900</th>\n",
       "      <td>7261</td>\n",
       "      <td>2017</td>\n",
       "      <td>Stochastic Submodular Maximization: The Case o...</td>\n",
       "      <td>stochastic optimization of continuous objectiv...</td>\n",
       "      <td>stochastic optimization continuous objective h...</td>\n",
       "      <td>187</td>\n",
       "      <td>115</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>3</td>\n",
       "      <td>[algorithm, problem, learning, function, bound...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3901</th>\n",
       "      <td>7262</td>\n",
       "      <td>2017</td>\n",
       "      <td>Affinity Clustering: Hierarchical Clustering a...</td>\n",
       "      <td>graph clustering is a fundamental task in many...</td>\n",
       "      <td>graph clustering fundamental task many data mi...</td>\n",
       "      <td>225</td>\n",
       "      <td>135</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0</td>\n",
       "      <td>[method, data, problem, algorithm, learning, m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3902</th>\n",
       "      <td>7263</td>\n",
       "      <td>2017</td>\n",
       "      <td>Unsupervised Transformation Learning via Conve...</td>\n",
       "      <td>our goal is to extract meaningful transformati...</td>\n",
       "      <td>goal extract meaningful transformation raw ima...</td>\n",
       "      <td>101</td>\n",
       "      <td>56</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "      <td>[model, network, neural, image, learning, task...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3903</th>\n",
       "      <td>7264</td>\n",
       "      <td>2017</td>\n",
       "      <td>A Sharp Error Analysis for the Fused Lasso, wi...</td>\n",
       "      <td>in the dimensional multiple changepoint detect...</td>\n",
       "      <td>dimensional multiple changepoint detection pro...</td>\n",
       "      <td>93</td>\n",
       "      <td>53</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0</td>\n",
       "      <td>[method, data, problem, algorithm, learning, m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3904</th>\n",
       "      <td>7265</td>\n",
       "      <td>2017</td>\n",
       "      <td>Linear Time Computation of Moments in Sum-Prod...</td>\n",
       "      <td>bayesian online algorithms for sum product net...</td>\n",
       "      <td>bayesian online algorithm sum product network ...</td>\n",
       "      <td>218</td>\n",
       "      <td>132</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0</td>\n",
       "      <td>[method, data, problem, algorithm, learning, m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3905</th>\n",
       "      <td>7266</td>\n",
       "      <td>2017</td>\n",
       "      <td>A Meta-Learning Perspective on Cold-Start Reco...</td>\n",
       "      <td>matrix factorization mf is one of the most pop...</td>\n",
       "      <td>matrix factorization mf one popular technique ...</td>\n",
       "      <td>137</td>\n",
       "      <td>92</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.17</td>\n",
       "      <td>2</td>\n",
       "      <td>[model, data, inference, learning, distributio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3906</th>\n",
       "      <td>7267</td>\n",
       "      <td>2017</td>\n",
       "      <td>Predicting Scene Parsing and Motion Dynamics i...</td>\n",
       "      <td>it is important for intelligent systems e g au...</td>\n",
       "      <td>important intelligent system e g autonomous ve...</td>\n",
       "      <td>237</td>\n",
       "      <td>144</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>[model, network, neural, image, learning, task...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3907</th>\n",
       "      <td>7268</td>\n",
       "      <td>2017</td>\n",
       "      <td>Sticking the Landing: Simple, Lower-Variance G...</td>\n",
       "      <td>we propose a simple and general variant of the...</td>\n",
       "      <td>propose simple general variant standard repara...</td>\n",
       "      <td>86</td>\n",
       "      <td>52</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0</td>\n",
       "      <td>[method, data, problem, algorithm, learning, m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3908</th>\n",
       "      <td>7269</td>\n",
       "      <td>2017</td>\n",
       "      <td>Efficient Approximation Algorithms for Strings...</td>\n",
       "      <td>sequence classification algorithms such as svm...</td>\n",
       "      <td>sequence classification algorithm svm require ...</td>\n",
       "      <td>193</td>\n",
       "      <td>117</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>[method, data, problem, algorithm, learning, m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3909</th>\n",
       "      <td>7270</td>\n",
       "      <td>2017</td>\n",
       "      <td>Kernel Feature Selection via Conditional Covar...</td>\n",
       "      <td>we propose a method for feature selection that...</td>\n",
       "      <td>propose method feature selection employ kernel...</td>\n",
       "      <td>87</td>\n",
       "      <td>52</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0</td>\n",
       "      <td>[method, data, problem, algorithm, learning, m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3910</th>\n",
       "      <td>7271</td>\n",
       "      <td>2017</td>\n",
       "      <td>Convergence of Gradient EM on Multi-component ...</td>\n",
       "      <td>in this paper we study convergence properties ...</td>\n",
       "      <td>paper study convergence property gradient vari...</td>\n",
       "      <td>113</td>\n",
       "      <td>72</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0</td>\n",
       "      <td>[method, data, problem, algorithm, learning, m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3911</th>\n",
       "      <td>7272</td>\n",
       "      <td>2017</td>\n",
       "      <td>Real Time Image Saliency for Black Box Classif...</td>\n",
       "      <td>in this work we develop a fast saliency detect...</td>\n",
       "      <td>work develop fast saliency detection method ap...</td>\n",
       "      <td>113</td>\n",
       "      <td>69</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>[model, network, neural, image, learning, task...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3912</th>\n",
       "      <td>7273</td>\n",
       "      <td>2017</td>\n",
       "      <td>Houdini: Fooling Deep Structured Visual and Sp...</td>\n",
       "      <td>generating adversarial examples is a critical ...</td>\n",
       "      <td>generating adversarial example critical step e...</td>\n",
       "      <td>118</td>\n",
       "      <td>71</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>[method, data, problem, algorithm, learning, m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3913</th>\n",
       "      <td>7274</td>\n",
       "      <td>2017</td>\n",
       "      <td>Efficient and Flexible Inference for Stochasti...</td>\n",
       "      <td>many real world dynamical systems are describe...</td>\n",
       "      <td>many real world dynamical system described sto...</td>\n",
       "      <td>61</td>\n",
       "      <td>41</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.26</td>\n",
       "      <td>2</td>\n",
       "      <td>[model, data, inference, learning, distributio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3914</th>\n",
       "      <td>7275</td>\n",
       "      <td>2017</td>\n",
       "      <td>When Cyclic Coordinate Descent Outperforms Ran...</td>\n",
       "      <td>the coordinate descent cd method is a classica...</td>\n",
       "      <td>coordinate descent cd method classical optimiz...</td>\n",
       "      <td>166</td>\n",
       "      <td>99</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.91</td>\n",
       "      <td>3</td>\n",
       "      <td>[algorithm, problem, learning, function, bound...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3915</th>\n",
       "      <td>7276</td>\n",
       "      <td>2017</td>\n",
       "      <td>Active Learning from Peers</td>\n",
       "      <td>this paper addresses the challenge of learning...</td>\n",
       "      <td>paper address challenge learning peer online m...</td>\n",
       "      <td>137</td>\n",
       "      <td>78</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.41</td>\n",
       "      <td>3</td>\n",
       "      <td>[algorithm, problem, learning, function, bound...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3916</th>\n",
       "      <td>7277</td>\n",
       "      <td>2017</td>\n",
       "      <td>Experimental Design for Learning Causal Graphs...</td>\n",
       "      <td>we consider the problem of learning causal str...</td>\n",
       "      <td>consider problem learning causal structure lat...</td>\n",
       "      <td>177</td>\n",
       "      <td>102</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.35</td>\n",
       "      <td>2</td>\n",
       "      <td>[model, data, inference, learning, distributio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3917</th>\n",
       "      <td>7278</td>\n",
       "      <td>2017</td>\n",
       "      <td>Learning to Model the Tail</td>\n",
       "      <td>we describe an approach to learning from long ...</td>\n",
       "      <td>describe approach learning long tailed imbalan...</td>\n",
       "      <td>228</td>\n",
       "      <td>125</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>[model, network, neural, image, learning, task...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3918</th>\n",
       "      <td>7279</td>\n",
       "      <td>2017</td>\n",
       "      <td>Stochastic Mirror Descent in Variationally Coh...</td>\n",
       "      <td>in this paper we examine a class of non convex...</td>\n",
       "      <td>paper examine class non convex stochastic opti...</td>\n",
       "      <td>131</td>\n",
       "      <td>86</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>3</td>\n",
       "      <td>[algorithm, problem, learning, function, bound...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3919</th>\n",
       "      <td>7280</td>\n",
       "      <td>2017</td>\n",
       "      <td>On Separability of Loss Functions, and Revisit...</td>\n",
       "      <td>we revisit the classical analysis of generativ...</td>\n",
       "      <td>revisit classical analysis generative v discri...</td>\n",
       "      <td>98</td>\n",
       "      <td>63</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>[method, data, problem, algorithm, learning, m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3920</th>\n",
       "      <td>7281</td>\n",
       "      <td>2017</td>\n",
       "      <td>Maxing and Ranking with Few Assumptions</td>\n",
       "      <td>pac maximum selection maxing and ranking of n ...</td>\n",
       "      <td>pac maximum selection maxing ranking n element...</td>\n",
       "      <td>84</td>\n",
       "      <td>53</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0</td>\n",
       "      <td>[method, data, problem, algorithm, learning, m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3921</th>\n",
       "      <td>7282</td>\n",
       "      <td>2017</td>\n",
       "      <td>On clustering network-valued data</td>\n",
       "      <td>community detection which focuses on clusterin...</td>\n",
       "      <td>community detection focus clustering node dete...</td>\n",
       "      <td>154</td>\n",
       "      <td>88</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>[model, data, inference, learning, distributio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3922</th>\n",
       "      <td>7283</td>\n",
       "      <td>2017</td>\n",
       "      <td>A General Framework for Robust Interactive Lea...</td>\n",
       "      <td>we propose a general framework for interactive...</td>\n",
       "      <td>propose general framework interactively learni...</td>\n",
       "      <td>249</td>\n",
       "      <td>136</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.55</td>\n",
       "      <td>3</td>\n",
       "      <td>[algorithm, problem, learning, function, bound...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3923</th>\n",
       "      <td>7284</td>\n",
       "      <td>2017</td>\n",
       "      <td>Multi-view Matrix Factorization for Linear Dyn...</td>\n",
       "      <td>we consider maximum likelihood estimation of l...</td>\n",
       "      <td>consider maximum likelihood estimation linear ...</td>\n",
       "      <td>138</td>\n",
       "      <td>92</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>[method, data, problem, algorithm, learning, m...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3924 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  year                                              title  \\\n",
       "0     1861  2000   Algorithms for Non-negative Matrix Factorization   \n",
       "1     1975  2001  Characterizing Neural Gain Control using Spike...   \n",
       "2     3163  2007                        Competition Adds Complexity   \n",
       "3     3164  2007  Efficient Principled Learning of Thin Junction...   \n",
       "4     3167  2007     Regularized Boost for Semi-Supervised Learning   \n",
       "5     3168  2007  Simplified Rules and Theoretical Analysis for ...   \n",
       "6     3169  2007  Predicting human gaze using low-level saliency...   \n",
       "7     3171  2007        Mining Internet-Scale Software Repositories   \n",
       "8     3172  2007        Continuous Time Particle Filtering for fMRI   \n",
       "9     3174  2007  An online Hebbian learning rule that performs ...   \n",
       "10    3176  2007              Discriminative K-means for Clustering   \n",
       "11    3178  2007  The Epoch-Greedy Algorithm for Multi-armed Ban...   \n",
       "12    3186  2007  Local Algorithms for Approximate Inference in ...   \n",
       "13    3188  2007                  Catching Change-points with Lasso   \n",
       "14    3190  2007  Evaluating Search Engines by Modeling the Rela...   \n",
       "15    3191  2007           Random Projections for Manifold Learning   \n",
       "16    3195  2007  Learning the structure of manifolds using rand...   \n",
       "17    3196  2007        A Probabilistic Approach to Language Change   \n",
       "18    3197  2007  Online Linear Regression and Its Application t...   \n",
       "19    3199  2007          Scan Strategies for Meteorological Radars   \n",
       "20    3200  2007  Fixing Max-Product: Convergent Message Passing...   \n",
       "21    3202  2007  Parallelizing Support Vector Machines on Distr...   \n",
       "22    3203  2007                 Predictive Matrix-Variate t Models   \n",
       "23    3204  2007  Modelling motion primitives and their timing i...   \n",
       "24    3206  2007                Learning the 2-D Topology of Images   \n",
       "25    3209  2007              On higher-order perceptron algorithms   \n",
       "26    3210  2007  Configuration Estimates Improve Pedestrian Fin...   \n",
       "27    3211  2007  Using Deep Belief Nets to Learn Covariance Ker...   \n",
       "28    3212  2007              Learning Bounds for Domain Adaptation   \n",
       "29    3213  2007  Unconstrained On-line Handwriting Recognition ...   \n",
       "...    ...   ...                                                ...   \n",
       "3894  7255  2017  Attend and Predict: Understanding Gene Regulat...   \n",
       "3895  7256  2017  Acceleration and Averaging in Stochastic Desce...   \n",
       "3896  7257  2017      Kernel functions based on triplet comparisons   \n",
       "3897  7258  2017  An Error Detection and Correction Framework fo...   \n",
       "3898  7259  2017  Style Transfer from Non-Parallel Text by Cross...   \n",
       "3899  7260  2017                     Cross-Spectral Factor Analysis   \n",
       "3900  7261  2017  Stochastic Submodular Maximization: The Case o...   \n",
       "3901  7262  2017  Affinity Clustering: Hierarchical Clustering a...   \n",
       "3902  7263  2017  Unsupervised Transformation Learning via Conve...   \n",
       "3903  7264  2017  A Sharp Error Analysis for the Fused Lasso, wi...   \n",
       "3904  7265  2017  Linear Time Computation of Moments in Sum-Prod...   \n",
       "3905  7266  2017  A Meta-Learning Perspective on Cold-Start Reco...   \n",
       "3906  7267  2017  Predicting Scene Parsing and Motion Dynamics i...   \n",
       "3907  7268  2017  Sticking the Landing: Simple, Lower-Variance G...   \n",
       "3908  7269  2017  Efficient Approximation Algorithms for Strings...   \n",
       "3909  7270  2017  Kernel Feature Selection via Conditional Covar...   \n",
       "3910  7271  2017  Convergence of Gradient EM on Multi-component ...   \n",
       "3911  7272  2017  Real Time Image Saliency for Black Box Classif...   \n",
       "3912  7273  2017  Houdini: Fooling Deep Structured Visual and Sp...   \n",
       "3913  7274  2017  Efficient and Flexible Inference for Stochasti...   \n",
       "3914  7275  2017  When Cyclic Coordinate Descent Outperforms Ran...   \n",
       "3915  7276  2017                         Active Learning from Peers   \n",
       "3916  7277  2017  Experimental Design for Learning Causal Graphs...   \n",
       "3917  7278  2017                         Learning to Model the Tail   \n",
       "3918  7279  2017  Stochastic Mirror Descent in Variationally Coh...   \n",
       "3919  7280  2017  On Separability of Loss Functions, and Revisit...   \n",
       "3920  7281  2017            Maxing and Ranking with Few Assumptions   \n",
       "3921  7282  2017                  On clustering network-valued data   \n",
       "3922  7283  2017  A General Framework for Robust Interactive Lea...   \n",
       "3923  7284  2017  Multi-view Matrix Factorization for Linear Dyn...   \n",
       "\n",
       "                                               abstract  \\\n",
       "0     non negative matrix factorization nmf has prev...   \n",
       "1     spike triggered averaging techniques are effec...   \n",
       "2     it is known that determinining whether a dec p...   \n",
       "3     we present the first truly polynomial algorith...   \n",
       "4     semi supervised inductive learning concerns ho...   \n",
       "5     we show that under suitable assumptions primar...   \n",
       "6     under natural viewing conditions human observe...   \n",
       "7     large repositories of source code create new c...   \n",
       "8     we construct a biologically motivated stochast...   \n",
       "9     independent component analysis ica is a powerf...   \n",
       "10    we present a theoretical study on the discrimi...   \n",
       "11    we present epoch greedy an algorithm for multi...   \n",
       "12    we present a new local approximation algorithm...   \n",
       "13    we propose a new approach for dealing with the...   \n",
       "14    we propose a model that leverages the millions...   \n",
       "15    we propose a novel method for em linear dimens...   \n",
       "16    we present a simple variant of the k d tree wh...   \n",
       "17    we present a probabilistic approach to languag...   \n",
       "18    we provide a provably efficient algorithm for ...   \n",
       "19    we address the problem of adaptive sensor cont...   \n",
       "20    we present a novel message passing algorithm f...   \n",
       "21    support vector machines svms suffer from a wid...   \n",
       "22    it is becoming increasingly important to learn...   \n",
       "23    biological movement is built up of sub blocks ...   \n",
       "24    we study the following question is the two dim...   \n",
       "25    a new algorithm for on line learning linear th...   \n",
       "26    fair discriminative pedestrian finders are now...   \n",
       "27    we show how to use unlabeled data and a deep b...   \n",
       "28    empirical risk minimization offers well known ...   \n",
       "29    on line handwriting recognition is unusual amo...   \n",
       "...                                                 ...   \n",
       "3894  the past decade has seen a revolution in genom...   \n",
       "3895  we formulate and study a general family of con...   \n",
       "3896  given only information in the form of similari...   \n",
       "3897  we define and study error detection and correc...   \n",
       "3898  this paper focuses on style transfer on the ba...   \n",
       "3899  in neuropsychiatric disorders such as schizoph...   \n",
       "3900  stochastic optimization of continuous objectiv...   \n",
       "3901  graph clustering is a fundamental task in many...   \n",
       "3902  our goal is to extract meaningful transformati...   \n",
       "3903  in the dimensional multiple changepoint detect...   \n",
       "3904  bayesian online algorithms for sum product net...   \n",
       "3905  matrix factorization mf is one of the most pop...   \n",
       "3906  it is important for intelligent systems e g au...   \n",
       "3907  we propose a simple and general variant of the...   \n",
       "3908  sequence classification algorithms such as svm...   \n",
       "3909  we propose a method for feature selection that...   \n",
       "3910  in this paper we study convergence properties ...   \n",
       "3911  in this work we develop a fast saliency detect...   \n",
       "3912  generating adversarial examples is a critical ...   \n",
       "3913  many real world dynamical systems are describe...   \n",
       "3914  the coordinate descent cd method is a classica...   \n",
       "3915  this paper addresses the challenge of learning...   \n",
       "3916  we consider the problem of learning causal str...   \n",
       "3917  we describe an approach to learning from long ...   \n",
       "3918  in this paper we examine a class of non convex...   \n",
       "3919  we revisit the classical analysis of generativ...   \n",
       "3920  pac maximum selection maxing and ranking of n ...   \n",
       "3921  community detection which focuses on clusterin...   \n",
       "3922  we propose a general framework for interactive...   \n",
       "3923  we consider maximum likelihood estimation of l...   \n",
       "\n",
       "                                          abstract_post  word_count_pre  \\\n",
       "0     non negative matrix factorization nmf previous...             108   \n",
       "1     spike triggered averaging technique effective ...              83   \n",
       "2     known determinining whether dec pomdp namely c...              70   \n",
       "3     present first truly polynomial algorithm learn...             144   \n",
       "4     semi supervised inductive learning concern lea...             123   \n",
       "5     show suitable assumption primarily linearizati...             158   \n",
       "6     natural viewing condition human observer shift...             204   \n",
       "7     large repository source code create new challe...             191   \n",
       "8     construct biologically motivated stochastic di...             102   \n",
       "9     independent component analysis ica powerful me...             104   \n",
       "10    present theoretical study discriminative clust...             191   \n",
       "11    present epoch greedy algorithm multi armed ban...              73   \n",
       "12    present new local approximation algorithm comp...             172   \n",
       "13    propose new approach dealing estimation locati...             103   \n",
       "14    propose model leverage million click received ...             214   \n",
       "15    propose novel method em linear dimensionality ...             143   \n",
       "16    present simple variant k tree automatically ad...              20   \n",
       "17    present probabilistic approach language change...             104   \n",
       "18    provide provably efficient algorithm learning ...              87   \n",
       "19    address problem adaptive sensor control dynami...             169   \n",
       "20    present novel message passing algorithm approx...             104   \n",
       "21    support vector machine svms suffer widely reco...             112   \n",
       "22    becoming increasingly important learn partiall...             132   \n",
       "23    biological movement built sub block motion pri...             170   \n",
       "24    study following question two dimensional struc...             159   \n",
       "25    new algorithm line learning linear threshold f...             103   \n",
       "26    fair discriminative pedestrian finder availabl...             116   \n",
       "27    show use unlabeled data deep belief net dbn le...             102   \n",
       "28    empirical risk minimization offer well known l...             143   \n",
       "29    line handwriting recognition unusual among seq...             128   \n",
       "...                                                 ...             ...   \n",
       "3894  past decade seen revolution genomic technology...             215   \n",
       "3895  formulate study general family continuous time...             134   \n",
       "3896  given information form similarity triplet obje...              85   \n",
       "3897  define study error detection correction task u...             141   \n",
       "3898  paper focus style transfer basis non parallel ...             111   \n",
       "3899  neuropsychiatric disorder schizophrenia depres...             169   \n",
       "3900  stochastic optimization continuous objective h...             187   \n",
       "3901  graph clustering fundamental task many data mi...             225   \n",
       "3902  goal extract meaningful transformation raw ima...             101   \n",
       "3903  dimensional multiple changepoint detection pro...              93   \n",
       "3904  bayesian online algorithm sum product network ...             218   \n",
       "3905  matrix factorization mf one popular technique ...             137   \n",
       "3906  important intelligent system e g autonomous ve...             237   \n",
       "3907  propose simple general variant standard repara...              86   \n",
       "3908  sequence classification algorithm svm require ...             193   \n",
       "3909  propose method feature selection employ kernel...              87   \n",
       "3910  paper study convergence property gradient vari...             113   \n",
       "3911  work develop fast saliency detection method ap...             113   \n",
       "3912  generating adversarial example critical step e...             118   \n",
       "3913  many real world dynamical system described sto...              61   \n",
       "3914  coordinate descent cd method classical optimiz...             166   \n",
       "3915  paper address challenge learning peer online m...             137   \n",
       "3916  consider problem learning causal structure lat...             177   \n",
       "3917  describe approach learning long tailed imbalan...             228   \n",
       "3918  paper examine class non convex stochastic opti...             131   \n",
       "3919  revisit classical analysis generative v discri...              98   \n",
       "3920  pac maximum selection maxing ranking n element...              84   \n",
       "3921  community detection focus clustering node dete...             154   \n",
       "3922  propose general framework interactively learni...             249   \n",
       "3923  consider maximum likelihood estimation linear ...             138   \n",
       "\n",
       "      word_count_post  Topic0  Topic1  Topic2  Topic3  Major_topic  \\\n",
       "0                  67    0.38    0.00    0.00    0.61            3   \n",
       "1                  52    0.16    0.82    0.01    0.01            1   \n",
       "2                  40    0.01    0.01    0.01    0.97            3   \n",
       "3                  89    0.57    0.00    0.30    0.12            0   \n",
       "4                  81    0.99    0.00    0.00    0.00            0   \n",
       "5                  99    0.41    0.58    0.00    0.00            1   \n",
       "6                 129    0.00    0.94    0.05    0.00            1   \n",
       "7                 130    0.08    0.39    0.53    0.00            2   \n",
       "8                  63    0.68    0.31    0.00    0.00            0   \n",
       "9                  62    0.54    0.45    0.00    0.00            0   \n",
       "10                117    0.99    0.00    0.00    0.00            0   \n",
       "11                 42    0.01    0.01    0.01    0.98            3   \n",
       "12                107    0.00    0.00    0.00    0.99            3   \n",
       "13                 58    0.99    0.01    0.00    0.00            0   \n",
       "14                115    0.46    0.00    0.35    0.19            0   \n",
       "15                 88    0.91    0.03    0.00    0.06            0   \n",
       "16                 12    0.76    0.02    0.20    0.02            0   \n",
       "17                 65    0.23    0.15    0.61    0.00            2   \n",
       "18                 55    0.01    0.01    0.01    0.98            3   \n",
       "19                 99    0.00    0.16    0.00    0.83            3   \n",
       "20                 62    0.29    0.00    0.00    0.70            3   \n",
       "21                 72    0.56    0.00    0.00    0.43            0   \n",
       "22                 77    0.48    0.00    0.51    0.00            2   \n",
       "23                102    0.04    0.84    0.11    0.00            1   \n",
       "24                 82    0.47    0.52    0.00    0.00            1   \n",
       "25                 68    0.45    0.00    0.00    0.54            3   \n",
       "26                 70    0.21    0.79    0.00    0.00            1   \n",
       "27                 61    0.51    0.33    0.00    0.16            0   \n",
       "28                 89    0.00    0.00    0.25    0.74            3   \n",
       "29                 80    0.00    0.85    0.14    0.00            1   \n",
       "...               ...     ...     ...     ...     ...          ...   \n",
       "3894              146    0.00    0.64    0.36    0.00            1   \n",
       "3895               76    0.11    0.00    0.00    0.88            3   \n",
       "3896               51    0.81    0.18    0.01    0.01            0   \n",
       "3897               81    0.06    0.89    0.04    0.00            1   \n",
       "3898               68    0.20    0.21    0.58    0.00            2   \n",
       "3899              107    0.24    0.57    0.18    0.00            1   \n",
       "3900              115    0.00    0.00    0.00    0.99            3   \n",
       "3901              135    0.57    0.00    0.00    0.42            0   \n",
       "3902               56    0.01    0.77    0.22    0.01            1   \n",
       "3903               53    0.98    0.01    0.01    0.01            0   \n",
       "3904              132    0.51    0.00    0.08    0.41            0   \n",
       "3905               92    0.00    0.27    0.56    0.17            2   \n",
       "3906              144    0.00    0.99    0.00    0.00            1   \n",
       "3907               52    0.89    0.01    0.10    0.01            0   \n",
       "3908              117    0.99    0.00    0.00    0.00            0   \n",
       "3909               52    0.98    0.01    0.01    0.01            0   \n",
       "3910               72    0.61    0.00    0.00    0.38            0   \n",
       "3911               69    0.14    0.85    0.00    0.00            1   \n",
       "3912               71    0.61    0.39    0.00    0.00            0   \n",
       "3913               41    0.31    0.01    0.42    0.26            2   \n",
       "3914               99    0.09    0.00    0.00    0.91            3   \n",
       "3915               78    0.22    0.08    0.28    0.41            3   \n",
       "3916              102    0.00    0.00    0.64    0.35            2   \n",
       "3917              125    0.26    0.57    0.16    0.00            1   \n",
       "3918               86    0.00    0.00    0.00    0.99            3   \n",
       "3919               63    0.92    0.00    0.07    0.00            0   \n",
       "3920               53    0.98    0.01    0.01    0.01            0   \n",
       "3921               88    0.32    0.27    0.41    0.00            2   \n",
       "3922              136    0.00    0.00    0.44    0.55            3   \n",
       "3923               92    0.86    0.00    0.13    0.00            0   \n",
       "\n",
       "                                               keywords  \n",
       "0     [algorithm, problem, learning, function, bound...  \n",
       "1     [model, network, neural, image, learning, task...  \n",
       "2     [algorithm, problem, learning, function, bound...  \n",
       "3     [method, data, problem, algorithm, learning, m...  \n",
       "4     [method, data, problem, algorithm, learning, m...  \n",
       "5     [model, network, neural, image, learning, task...  \n",
       "6     [model, network, neural, image, learning, task...  \n",
       "7     [model, data, inference, learning, distributio...  \n",
       "8     [method, data, problem, algorithm, learning, m...  \n",
       "9     [method, data, problem, algorithm, learning, m...  \n",
       "10    [method, data, problem, algorithm, learning, m...  \n",
       "11    [algorithm, problem, learning, function, bound...  \n",
       "12    [algorithm, problem, learning, function, bound...  \n",
       "13    [method, data, problem, algorithm, learning, m...  \n",
       "14    [method, data, problem, algorithm, learning, m...  \n",
       "15    [method, data, problem, algorithm, learning, m...  \n",
       "16    [method, data, problem, algorithm, learning, m...  \n",
       "17    [model, data, inference, learning, distributio...  \n",
       "18    [algorithm, problem, learning, function, bound...  \n",
       "19    [algorithm, problem, learning, function, bound...  \n",
       "20    [algorithm, problem, learning, function, bound...  \n",
       "21    [method, data, problem, algorithm, learning, m...  \n",
       "22    [model, data, inference, learning, distributio...  \n",
       "23    [model, network, neural, image, learning, task...  \n",
       "24    [model, network, neural, image, learning, task...  \n",
       "25    [algorithm, problem, learning, function, bound...  \n",
       "26    [model, network, neural, image, learning, task...  \n",
       "27    [method, data, problem, algorithm, learning, m...  \n",
       "28    [algorithm, problem, learning, function, bound...  \n",
       "29    [model, network, neural, image, learning, task...  \n",
       "...                                                 ...  \n",
       "3894  [model, network, neural, image, learning, task...  \n",
       "3895  [algorithm, problem, learning, function, bound...  \n",
       "3896  [method, data, problem, algorithm, learning, m...  \n",
       "3897  [model, network, neural, image, learning, task...  \n",
       "3898  [model, data, inference, learning, distributio...  \n",
       "3899  [model, network, neural, image, learning, task...  \n",
       "3900  [algorithm, problem, learning, function, bound...  \n",
       "3901  [method, data, problem, algorithm, learning, m...  \n",
       "3902  [model, network, neural, image, learning, task...  \n",
       "3903  [method, data, problem, algorithm, learning, m...  \n",
       "3904  [method, data, problem, algorithm, learning, m...  \n",
       "3905  [model, data, inference, learning, distributio...  \n",
       "3906  [model, network, neural, image, learning, task...  \n",
       "3907  [method, data, problem, algorithm, learning, m...  \n",
       "3908  [method, data, problem, algorithm, learning, m...  \n",
       "3909  [method, data, problem, algorithm, learning, m...  \n",
       "3910  [method, data, problem, algorithm, learning, m...  \n",
       "3911  [model, network, neural, image, learning, task...  \n",
       "3912  [method, data, problem, algorithm, learning, m...  \n",
       "3913  [model, data, inference, learning, distributio...  \n",
       "3914  [algorithm, problem, learning, function, bound...  \n",
       "3915  [algorithm, problem, learning, function, bound...  \n",
       "3916  [model, data, inference, learning, distributio...  \n",
       "3917  [model, network, neural, image, learning, task...  \n",
       "3918  [algorithm, problem, learning, function, bound...  \n",
       "3919  [method, data, problem, algorithm, learning, m...  \n",
       "3920  [method, data, problem, algorithm, learning, m...  \n",
       "3921  [model, data, inference, learning, distributio...  \n",
       "3922  [algorithm, problem, learning, function, bound...  \n",
       "3923  [method, data, problem, algorithm, learning, m...  \n",
       "\n",
       "[3924 rows x 13 columns]"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "reccomended =reccomendation(lda_df,3167,columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3433</th>\n",
       "      <td>6794</td>\n",
       "      <td>Consistent Multitask Learning with Nonlinear O...</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3361</th>\n",
       "      <td>6722</td>\n",
       "      <td>Fixed-Rank Approximation of a Positive-Semidef...</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>690</th>\n",
       "      <td>4000</td>\n",
       "      <td>Sufficient Conditions for Generating Group Lev...</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1877</th>\n",
       "      <td>5237</td>\n",
       "      <td>Learning with Fredholm Kernels</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>678</th>\n",
       "      <td>3988</td>\n",
       "      <td>Efficient and Robust Feature Selection via Joi...</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1879</th>\n",
       "      <td>5239</td>\n",
       "      <td>Kernel Mean Estimation via Spectral Filtering</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3376</th>\n",
       "      <td>6737</td>\n",
       "      <td>Generalized Linear Model Regression under Dist...</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1880</th>\n",
       "      <td>5240</td>\n",
       "      <td>Subspace Embeddings for the Polynomial Kernel</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1284</th>\n",
       "      <td>4626</td>\n",
       "      <td>Exact and Stable Recovery of Sequences of Sign...</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>655</th>\n",
       "      <td>3965</td>\n",
       "      <td>Network Flow Algorithms for Structured Sparsity</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>644</th>\n",
       "      <td>3954</td>\n",
       "      <td>Learning Kernels with Radiuses of Minimum Encl...</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1288</th>\n",
       "      <td>4630</td>\n",
       "      <td>Compressive Sensing MRI with Wavelet Tree Spar...</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2474</th>\n",
       "      <td>5834</td>\n",
       "      <td>Structured Estimation with Atomic Norms: Gener...</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3390</th>\n",
       "      <td>6751</td>\n",
       "      <td>Linear regression without correspondence</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>626</th>\n",
       "      <td>3936</td>\n",
       "      <td>Relaxed Clipping: A Global Training Method for...</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2978</th>\n",
       "      <td>6338</td>\n",
       "      <td>Stein Variational Gradient Descent: A General ...</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1566</th>\n",
       "      <td>4923</td>\n",
       "      <td>BIG &amp; QUIC: Sparse Inverse Covariance Estimati...</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2469</th>\n",
       "      <td>5829</td>\n",
       "      <td>HONOR: Hybrid Optimization for NOn-convex Regu...</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1274</th>\n",
       "      <td>4615</td>\n",
       "      <td>Matrix reconstruction with the local max norm</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>716</th>\n",
       "      <td>4026</td>\n",
       "      <td>Random Conic Pursuit for Semidefinite Programming</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3319</th>\n",
       "      <td>6680</td>\n",
       "      <td>A New Theory for Matrix Completion</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>729</th>\n",
       "      <td>4039</td>\n",
       "      <td>Random Projection Trees Revisited</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1773</th>\n",
       "      <td>5130</td>\n",
       "      <td>Robust Transfer Principal Component Analysis w...</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2541</th>\n",
       "      <td>5901</td>\n",
       "      <td>Sparse PCA via Bipartite Matchings</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3262</th>\n",
       "      <td>6623</td>\n",
       "      <td>Parametric Simplex Method for Sparse Learning</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>6357</td>\n",
       "      <td>High-Rank Matrix Completion and Clustering und...</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>4110</td>\n",
       "      <td>An Inverse Power Method for Nonlinear Eigenpro...</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3263</th>\n",
       "      <td>6624</td>\n",
       "      <td>Group Sparse Additive Machine</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788</th>\n",
       "      <td>4099</td>\n",
       "      <td>Sparse Inverse Covariance Selection via Altern...</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785</th>\n",
       "      <td>4096</td>\n",
       "      <td>The LASSO risk: asymptotic results and real wo...</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>3691</td>\n",
       "      <td>Group Sparse Coding</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3499</th>\n",
       "      <td>6860</td>\n",
       "      <td>Dual Discriminator Generative Adversarial Nets</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867</th>\n",
       "      <td>5227</td>\n",
       "      <td>Factoring Variations in Natural Images with De...</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3573</th>\n",
       "      <td>6934</td>\n",
       "      <td>Bayesian Inference of Individualized Treatment...</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3338</th>\n",
       "      <td>6699</td>\n",
       "      <td>Learning to Pivot with Adversarial Networks</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2603</th>\n",
       "      <td>5963</td>\n",
       "      <td>Rectified Factor Networks</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2729</th>\n",
       "      <td>6089</td>\n",
       "      <td>Graphons, mergeons, and so on!</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3602</th>\n",
       "      <td>6963</td>\n",
       "      <td>Joint distribution optimal transportation for ...</td>\n",
       "      <td>0.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1233</th>\n",
       "      <td>4568</td>\n",
       "      <td>Dynamic Pruning of Factor Graphs for Maximum M...</td>\n",
       "      <td>0.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3739</th>\n",
       "      <td>7100</td>\n",
       "      <td>Excess Risk Bounds for the Bayes Risk using Va...</td>\n",
       "      <td>0.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1267</th>\n",
       "      <td>4608</td>\n",
       "      <td>A systematic approach to extracting semantic i...</td>\n",
       "      <td>0.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3022</th>\n",
       "      <td>6382</td>\n",
       "      <td>Leveraging Sparsity for Efficient Submodular D...</td>\n",
       "      <td>0.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3719</th>\n",
       "      <td>7080</td>\n",
       "      <td>Maximum Margin Interval Trees</td>\n",
       "      <td>0.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3843</th>\n",
       "      <td>7204</td>\n",
       "      <td>Spectrally-normalized margin bounds for neural...</td>\n",
       "      <td>0.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1602</th>\n",
       "      <td>4959</td>\n",
       "      <td>Marginals-to-Models Reducibility</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2329</th>\n",
       "      <td>5689</td>\n",
       "      <td>Rate-Agnostic (Causal) Structure Learning</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1287</th>\n",
       "      <td>4629</td>\n",
       "      <td>Distributed Probabilistic Learning for Camera ...</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2405</th>\n",
       "      <td>5765</td>\n",
       "      <td>The Human Kernel</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2093</th>\n",
       "      <td>5453</td>\n",
       "      <td>(Almost) No Label No Cry</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3454</th>\n",
       "      <td>6815</td>\n",
       "      <td>MMD GAN: Towards Deeper Understanding of Momen...</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2036</th>\n",
       "      <td>5396</td>\n",
       "      <td>Distributed Power-law Graph Computing: Theoret...</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2318</th>\n",
       "      <td>5678</td>\n",
       "      <td>Local Expectation Gradients for Black Box Vari...</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1559</th>\n",
       "      <td>4916</td>\n",
       "      <td>Approximate Inference in Continuous Determinan...</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3334</th>\n",
       "      <td>6695</td>\n",
       "      <td>Learning Overcomplete HMMs</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2757</th>\n",
       "      <td>6117</td>\n",
       "      <td>Bayesian Optimization with Robust Bayesian Neu...</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1858</th>\n",
       "      <td>5215</td>\n",
       "      <td>Reservoir Boosting : Between Online and Offlin...</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3744</th>\n",
       "      <td>7105</td>\n",
       "      <td>Identifying Outlier Arms in Multi-Armed Bandit</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1608</th>\n",
       "      <td>4965</td>\n",
       "      <td>Embed and Project: Discrete Sampling with Univ...</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3094</th>\n",
       "      <td>6454</td>\n",
       "      <td>A Non-parametric Learning Method for Confident...</td>\n",
       "      <td>0.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1383</th>\n",
       "      <td>4731</td>\n",
       "      <td>Clustering Aggregation as Maximum-Weight Indep...</td>\n",
       "      <td>0.79</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1439 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                              title  error\n",
       "3433  6794  Consistent Multitask Learning with Nonlinear O...   0.00\n",
       "3361  6722  Fixed-Rank Approximation of a Positive-Semidef...   0.00\n",
       "690   4000  Sufficient Conditions for Generating Group Lev...   0.00\n",
       "1877  5237                     Learning with Fredholm Kernels   0.00\n",
       "678   3988  Efficient and Robust Feature Selection via Joi...   0.00\n",
       "1879  5239      Kernel Mean Estimation via Spectral Filtering   0.00\n",
       "3376  6737  Generalized Linear Model Regression under Dist...   0.00\n",
       "1880  5240      Subspace Embeddings for the Polynomial Kernel   0.00\n",
       "1284  4626  Exact and Stable Recovery of Sequences of Sign...   0.00\n",
       "655   3965    Network Flow Algorithms for Structured Sparsity   0.00\n",
       "644   3954  Learning Kernels with Radiuses of Minimum Encl...   0.00\n",
       "1288  4630  Compressive Sensing MRI with Wavelet Tree Spar...   0.00\n",
       "2474  5834  Structured Estimation with Atomic Norms: Gener...   0.00\n",
       "3390  6751           Linear regression without correspondence   0.00\n",
       "626   3936  Relaxed Clipping: A Global Training Method for...   0.00\n",
       "2978  6338  Stein Variational Gradient Descent: A General ...   0.00\n",
       "1566  4923  BIG & QUIC: Sparse Inverse Covariance Estimati...   0.00\n",
       "2469  5829  HONOR: Hybrid Optimization for NOn-convex Regu...   0.00\n",
       "1274  4615      Matrix reconstruction with the local max norm   0.00\n",
       "716   4026  Random Conic Pursuit for Semidefinite Programming   0.00\n",
       "3319  6680                 A New Theory for Matrix Completion   0.00\n",
       "729   4039                  Random Projection Trees Revisited   0.00\n",
       "1773  5130  Robust Transfer Principal Component Analysis w...   0.00\n",
       "2541  5901                 Sparse PCA via Bipartite Matchings   0.00\n",
       "3262  6623      Parametric Simplex Method for Sparse Learning   0.00\n",
       "2997  6357  High-Rank Matrix Completion and Clustering und...   0.00\n",
       "799   4110  An Inverse Power Method for Nonlinear Eigenpro...   0.00\n",
       "3263  6624                      Group Sparse Additive Machine   0.00\n",
       "788   4099  Sparse Inverse Covariance Selection via Altern...   0.00\n",
       "785   4096  The LASSO risk: asymptotic results and real wo...   0.00\n",
       "...    ...                                                ...    ...\n",
       "386   3691                                Group Sparse Coding   0.72\n",
       "3499  6860     Dual Discriminator Generative Adversarial Nets   0.72\n",
       "1867  5227  Factoring Variations in Natural Images with De...   0.72\n",
       "3573  6934  Bayesian Inference of Individualized Treatment...   0.72\n",
       "3338  6699        Learning to Pivot with Adversarial Networks   0.72\n",
       "2603  5963                          Rectified Factor Networks   0.72\n",
       "2729  6089                     Graphons, mergeons, and so on!   0.72\n",
       "3602  6963  Joint distribution optimal transportation for ...   0.73\n",
       "1233  4568  Dynamic Pruning of Factor Graphs for Maximum M...   0.73\n",
       "3739  7100  Excess Risk Bounds for the Bayes Risk using Va...   0.73\n",
       "1267  4608  A systematic approach to extracting semantic i...   0.73\n",
       "3022  6382  Leveraging Sparsity for Efficient Submodular D...   0.73\n",
       "3719  7080                      Maximum Margin Interval Trees   0.73\n",
       "3843  7204  Spectrally-normalized margin bounds for neural...   0.73\n",
       "1602  4959                   Marginals-to-Models Reducibility   0.74\n",
       "2329  5689          Rate-Agnostic (Causal) Structure Learning   0.74\n",
       "1287  4629  Distributed Probabilistic Learning for Camera ...   0.75\n",
       "2405  5765                                   The Human Kernel   0.75\n",
       "2093  5453                           (Almost) No Label No Cry   0.75\n",
       "3454  6815  MMD GAN: Towards Deeper Understanding of Momen...   0.75\n",
       "2036  5396  Distributed Power-law Graph Computing: Theoret...   0.75\n",
       "2318  5678  Local Expectation Gradients for Black Box Vari...   0.76\n",
       "1559  4916  Approximate Inference in Continuous Determinan...   0.76\n",
       "3334  6695                         Learning Overcomplete HMMs   0.76\n",
       "2757  6117  Bayesian Optimization with Robust Bayesian Neu...   0.76\n",
       "1858  5215  Reservoir Boosting : Between Online and Offlin...   0.76\n",
       "3744  7105     Identifying Outlier Arms in Multi-Armed Bandit   0.76\n",
       "1608  4965  Embed and Project: Discrete Sampling with Univ...   0.76\n",
       "3094  6454  A Non-parametric Learning Method for Confident...   0.77\n",
       "1383  4731  Clustering Aggregation as Maximum-Weight Indep...   0.79\n",
       "\n",
       "[1439 rows x 3 columns]"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reccomended.sort_values('error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'semi supervised inductive learning concerns how to learn a decision rule from a data set containing both labeled and unlabeled data several boosting algorithms have been extended to semi supervised learning with various strategies to our knowledge however none of them takes local smoothness constraints among data into account during ensemble learning in this paper we introduce a local smoothness regularizer to semi supervised boosting algorithms based on the universal optimization framework of margin cost functionals our regularizer is applicable to existing semi supervised boosting algorithms to improve their generalization and speed up their training comparative results on synthetic benchmark and real world tasks demonstrate the effectiveness of our local smoothness regularizer we discuss relevant issues and relate our regularizer to previous work '"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_df.iloc[4]['abstract']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'in this paper we propose a framework for supervised and semi supervised learning based on reformulating the learning problem as a regularized fredholm integral equation our approach fits naturally into the kernel framework and can be interpreted as constructing new data dependent kernels which we call fredholm kernels we proceed to discuss the noise assumption for semi supervised learning and provide evidence evidence both theoretical and experimental that fredholm kernels can effectively utilize unlabeled data under the noise assumption we demonstrate that methods based on fredholm learning show very competitive performance in the standard semi supervised learning setting '"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_df.iloc[1877]['abstract']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
